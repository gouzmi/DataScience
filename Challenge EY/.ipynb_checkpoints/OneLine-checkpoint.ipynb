{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from math import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_centre = 3760901.5068\n",
    "y_centre = -19238905.6133\n",
    "\n",
    "train = pd.read_csv('data_train.csv')\n",
    "test = pd.read_csv('data_test.csv')\n",
    "train = train.drop(['Unnamed: 0'],axis=1)\n",
    "test = test.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "tr = test.loc[test.x_exit.isnull()]\n",
    "\n",
    "def conv(time_1):   \n",
    "    sec1 = 3600*int(time_1[0:2]) + 60*int(time_1[3:5]) + int(time_1[6:8])                                                                                                                                \n",
    "    return (sec1)\n",
    "\n",
    "def distance(x1,x2,y1,y2):\n",
    "    dist = np.sqrt(((x2-x1)**2)+((y2-y1)**2))\n",
    "    return dist\n",
    "\n",
    "def ecartTemps(t1,t2):\n",
    "    ecart= t2-t1\n",
    "    return ecart\n",
    "\n",
    "def distanceCentre(x,y):\n",
    "    dx = max(0,abs(x_centre-x)-10000)\n",
    "    dy = max(0,abs(y_centre-y)-30000)\n",
    "    return (dx**2+dy**2)\n",
    "\n",
    "ecartTemps = np.vectorize(ecartTemps)\n",
    "\n",
    "distance = np.vectorize(distance)\n",
    "distanceCentre = np.vectorize(distanceCentre)\n",
    "#vitesses négatives\n",
    "\n",
    "\n",
    "\n",
    "test.vmin[test.vmin < 0] = np.NaN\n",
    "test.vmean[test.vmean < 0] = np.NaN\n",
    "test.vmax[test.vmax < 0] = np.NaN\n",
    "\n",
    "train.vmin[train.vmin < 0] = np.NaN\n",
    "train.vmean[train.vmean < 0] = np.NaN\n",
    "train.vmax[train.vmax < 0] = np.NaN\n",
    "\n",
    "#incohérences\n",
    "train['vmean'][(train.time_entry==train.time_exit)] = 0\n",
    "train['vmin'][(train.time_entry==train.time_exit)] = 0\n",
    "train['vmax'][(train.time_entry==train.time_exit)] = 0\n",
    "\n",
    "test['vmean'][(test.time_entry==test.time_exit)] = 0\n",
    "test['vmin'][(test.time_entry==test.time_exit)] = 0\n",
    "test['vmax'][(test.time_entry==test.time_exit)] = 0\n",
    "\n",
    "train['vmax'][(train.x_entry==train.x_exit)&(train.y_entry==train.y_exit)] = 0\n",
    "train['vmin'][(train.x_entry==train.x_exit)&(train.y_entry==train.y_exit)] = 0\n",
    "train['vmean'][(train.x_entry==train.x_exit)&(train.y_entry==train.y_exit)] = 0\n",
    "\n",
    "test['vmax'][(test.x_entry==test.x_exit)&(test.y_entry==test.y_exit)] = 0\n",
    "test['vmin'][(test.x_entry==test.x_exit)&(test.y_entry==test.y_exit)] = 0\n",
    "test['vmean'][(test.x_entry==test.x_exit)&(test.y_entry==test.y_exit)] = 0\n",
    "\n",
    "#incohérences 2 \n",
    "\n",
    "# train['vmean'][(train.time_entry!=train.time_exit)&(train.vmean == 0)] = np.NaN\n",
    "# train['vmin'][(train.time_entry!=train.time_exit)&(train.vmin == 0)] = np.NaN\n",
    "# train['vmax'][(train.time_entry!=train.time_exit)&(train.vmax == 0)] = np.NaN\n",
    "\n",
    "# test['vmean'][(test.time_entry!=test.time_exit)&(test.vmean == 0)] = np.NaN\n",
    "# test['vmin'][(test.time_entry!=test.time_exit)&(test.vmin == 0)] = np.NaN\n",
    "# test['vmax'][(test.time_entry!=test.time_exit)&(test.vmax == 0)] = np.NaN\n",
    "\n",
    "#train['vmax'][((train.x_entry!=train.x_exit)|(train.y_entry!=train.y_exit))&(train.vmax == 0)] = np.NaN\n",
    "#train['vmin'][((train.x_entry!=train.x_exit)|(train.y_entry!=train.y_exit))&(train.vmin == 0)] = np.NaN\n",
    "#train['vmean'][((train.x_entry!=train.x_exit)|(train.y_entry!=train.y_exit))&(train.vmean == 0)] = np.NaN\n",
    "\n",
    "#test['vmax'][((test.x_entry!=test.x_exit)|(test.y_entry!=test.y_exit))&(test.vmax == 0)] = np.NaN\n",
    "#test['vmin'][((test.x_entry!=test.x_exit)|(test.y_entry!=test.y_exit))&(test.vmin == 0)] = np.NaN\n",
    "#test['vmean'][((test.x_entry!=test.x_exit)|(test.y_entry!=test.y_exit))&(test.vmean == 0)] = np.NaN\n",
    "\n",
    "#outliers\n",
    "train.vmean = train.vmean.loc[(train.vmean<90)]\n",
    "train.vmax = train.vmean.loc[(train.vmax<90)]\n",
    "train.vmin = train.vmean.loc[(train.vmin<90)]\n",
    "\n",
    "\n",
    "#nan by mean\n",
    "train['vmax']=train['vmax'].replace( np.NaN , train['vmax'].mean() )\n",
    "train['vmin']=train['vmin'].replace( np.NaN , train['vmin'].mean() )\n",
    "train['vmean']=train['vmean'].replace( np.NaN , train['vmean'].mean() )\n",
    "\n",
    "test['vmax']=test['vmax'].replace( np.NaN , test['vmax'].mean() )\n",
    "test['vmin']=test['vmin'].replace( np.NaN , test['vmin'].mean() )\n",
    "test['vmean']=test['vmean'].replace( np.NaN , test['vmean'].mean() )\n",
    "\n",
    "# trainTempVmean = train.loc[(train.vmean>0)]\n",
    "# trainTempVmean = trainTempVmean.dropna()\n",
    "# trainTempVmean = trainTempVmean.vmean.mean()\n",
    "\n",
    "# trainTempVmax = train.loc[(train.vmax>0)]\n",
    "# trainTempVmax = trainTempVmax.dropna()\n",
    "# trainTempVmax = trainTempVmax.vmax.mean()\n",
    "\n",
    "# trainTempVmin = train.loc[(train.vmin>0)]\n",
    "# trainTempVmin = trainTempVmin.dropna()\n",
    "# trainTempVmin = trainTempVmin.vmin.mean()\n",
    "\n",
    "# testTempVmean = test.loc[(test.vmean>0)]\n",
    "# testTempVmean = testTempVmean.dropna()\n",
    "# testTempVmean = testTempVmean.vmean.mean()\n",
    "\n",
    "# testTempVmax = test.loc[(test.vmax>0)]\n",
    "# testTempVmax = testTempVmax.dropna()\n",
    "# testTempVmax = testTempVmax.vmax.mean()\n",
    "\n",
    "# testTempVmin = test.loc[(test.vmin>0)]\n",
    "# testTempVmin = testTempVmin.dropna()\n",
    "# testTempVmin = testTempVmin.vmin.mean()\n",
    "\n",
    "\n",
    "# train['vmax']=train['vmax'].replace( np.NaN , trainTempVmax)\n",
    "# train['vmin']=train['vmin'].replace( np.NaN , trainTempVmin)\n",
    "# train['vmean']=train['vmean'].replace( np.NaN , trainTempVmean)\n",
    "# test['vmax']=test['vmax'].replace( np.NaN , testTempVmax)\n",
    "# test['vmin']=test['vmin'].replace( np.NaN , testTempVmin)\n",
    "# test['vmean']=test['vmean'].replace( np.NaN , testTempVmean)\n",
    "\n",
    "vec_conv =  np.vectorize(conv)\n",
    "train.time_entry=vec_conv(train.time_entry)\n",
    "train.time_exit=vec_conv(train.time_exit)\n",
    "\n",
    "test.time_entry=vec_conv(test.time_entry)\n",
    "test.time_exit=vec_conv(test.time_exit)\n",
    "\n",
    "#moments\n",
    "# train['nuit']= 0\n",
    "# train['nuit'][(train.time_entry<28800)]=1\n",
    "# train['matin']= 0\n",
    "# train['matin'][(train.time_entry<43200)&(train.time_entry>28800)]=1\n",
    "# train['aprem']= 0\n",
    "# train['aprem'][(train.time_entry>=43200)]=1\n",
    "\n",
    "# test['nuit']= 0\n",
    "# test['nuit'][(test.time_entry<28800)]=1\n",
    "# test['matin']= 0\n",
    "# test['matin'][(test.time_entry<43200)&(test.time_entry>28800)]=1\n",
    "# test['aprem']= 0\n",
    "# test['aprem'][(test.time_entry>=43200)]=1\n",
    "\n",
    "train['duree']=ecartTemps(train.time_entry,train.time_exit)\n",
    "test['duree']=ecartTemps(test.time_entry,test.time_exit)\n",
    "train = train.drop(['time_entry','time_exit'],axis=1)\n",
    "test = test.drop(['time_entry','time_exit'],axis=1)\n",
    "\n",
    "#train['distCenter']=distanceCentre(train.x_entry,train.y_entry)\n",
    "#test['distCenter']=distanceCentre(test.x_entry,test.y_entry)\n",
    "\n",
    "train['distCenter_entry']=distanceCentre(train.x_entry,train.y_entry)\n",
    "test['distCenter_entry']=distanceCentre(test.x_entry,test.y_entry)\n",
    "\n",
    "train['distCenter_exit']=distanceCentre(train.x_exit,train.y_exit)\n",
    "test['distCenter_exit']=distanceCentre(test.x_exit,test.y_exit)\n",
    "\n",
    "train['Ecart_dist']=train['distCenter_exit']-train['distCenter_entry']\n",
    "test['Ecart_dist']=test['distCenter_exit']-test['distCenter_entry']\n",
    "\n",
    "#angles\n",
    "\n",
    "u = np.array([train.x_exit,train.y_exit])-np.array([train.x_entry,train.y_entry])\n",
    "v = np.array([x_centre-train.x_entry,y_centre-train.y_entry])\n",
    "\n",
    "angle_train = []\n",
    "for i in range(u.shape[1]):\n",
    "    scalar = (np.dot([u[0][i],u[1][i]],[v[0][i],v[1][i]]))\n",
    "    u_norm = (np.linalg.norm([u[0][i],u[1][i]]))\n",
    "    v_norm = (np.linalg.norm([v[0][i],v[1][i]]))\n",
    "    angle_train.append(degrees(acos(scalar/(u_norm*v_norm))))\n",
    "    \n",
    "u = np.array([test.x_exit,test.y_exit])-np.array([test.x_entry,test.y_entry])\n",
    "v = np.array([x_centre-test.x_entry,y_centre-test.y_entry])\n",
    "\n",
    "angle_test = []\n",
    "for i in range(u.shape[1]):\n",
    "    scalar = (np.dot([u[0][i],u[1][i]],[v[0][i],v[1][i]]))\n",
    "    u_norm = (np.linalg.norm([u[0][i],u[1][i]]))\n",
    "    v_norm = (np.linalg.norm([v[0][i],v[1][i]]))\n",
    "    angle_test.append(degrees(acos(scalar/(u_norm*v_norm))))\n",
    "\n",
    "#application\n",
    "\n",
    "train['angle']=angle_train\n",
    "test['angle']=angle_test\n",
    "\n",
    "# u = np.array([3770901.5068-x_centre,-19208905.6133-y_centre])\n",
    "\n",
    "# v = np.array([x_centre-train.x_entry,y_centre-train.y_entry])\n",
    "# angle_entry_train = []\n",
    "# for i in range(v.shape[1]):\n",
    "#     scalar = (np.dot([u[0],u[1]],[v[0][i],v[1][i]]))\n",
    "#     u_norm = (np.linalg.norm(u))\n",
    "#     v_norm = (np.linalg.norm([v[0][i],v[1][i]]))\n",
    "#     angle_entry_train.append(degrees(acos(scalar/(u_norm*v_norm))))\n",
    "\n",
    "# v = np.array([x_centre-train.x_exit,y_centre-train.y_exit])\n",
    "# angle_exit_train = []\n",
    "# for i in range(v.shape[1]):\n",
    "#     scalar = (np.dot([u[0],u[1]],[v[0][i],v[1][i]]))\n",
    "#     u_norm = (np.linalg.norm(u))\n",
    "#     v_norm = (np.linalg.norm([v[0][i],v[1][i]]))\n",
    "#     angle_exit_train.append(degrees(acos(scalar/(u_norm*v_norm))))\n",
    "\n",
    "# v = np.array([x_centre-test.x_entry,y_centre-test.y_entry])\n",
    "# angle_entry_test = []\n",
    "# for i in range(v.shape[1]):\n",
    "#     scalar = (np.dot([u[0],u[1]],[v[0][i],v[1][i]]))\n",
    "#     u_norm = (np.linalg.norm(u))\n",
    "#     v_norm = (np.linalg.norm([v[0][i],v[1][i]]))\n",
    "#     angle_entry_test.append(degrees(acos(scalar/(u_norm*v_norm))))\n",
    "    \n",
    "# v = np.array([x_centre-test.x_exit,y_centre-test.y_exit])\n",
    "# angle_exit_test = []\n",
    "# for i in range(v.shape[1]):\n",
    "#     scalar = (np.dot([u[0],u[1]],[v[0][i],v[1][i]]))\n",
    "#     u_norm = (np.linalg.norm(u))\n",
    "#     v_norm = (np.linalg.norm([v[0][i],v[1][i]]))\n",
    "#     angle_exit_test.append(degrees(acos(scalar/(u_norm*v_norm))))\n",
    "\n",
    "# #application\n",
    "\n",
    "# train['angle_entry']=angle_entry_train\n",
    "# test['angle_entry']=angle_entry_test\n",
    "# train['angle_exit']=angle_exit_train\n",
    "# test['angle_exit']=angle_exit_test\n",
    "\n",
    "# #(3750901.5068+3770901.5068)/2 x centre\n",
    "# # = 3760901.5068\n",
    "# #(-19268905.6133+-19208905.6133)/2\n",
    "# # = -19238905.6133\n",
    "# Center = distance(train.x_entry,3760901.5068,train.y_entry,-19238905.6133)\n",
    "# train['Center'] = Center\n",
    "\n",
    "train['city_center'] = 0\n",
    "train['city_center'][(train.x_exit>=3750901.5068) & (train.x_exit<=3770901.5068)&(train.y_exit>=(-19268905.6133)) & (train.y_exit<=(-19208905.6133))]=1\n",
    "\n",
    "# train.drop(['x_entry', 'x_exit','y_exit','y_entry'], axis=1, inplace=True)\n",
    "# test.drop(['x_entry', 'x_exit','y_exit','y_entry'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3) :\n",
    "    \n",
    "    if(np.array(a).shape[0])>=3:\n",
    "        ret = np.cumsum(a, dtype=float)\n",
    "        ret[n:] = ret[n:] - ret[:-n]\n",
    "        return ret[n - 1:] / n\n",
    "    elif(np.array(a).shape[0])==0:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        ret = np.cumsum(a, dtype=float)\n",
    "        ret[1:] = ret[1:] - ret[:-1]\n",
    "        return ret[0:] / 1\n",
    "\n",
    "def findOptimalTreshold(model, nb_splits):\n",
    "    listTreshold = []\n",
    "    listScore = []\n",
    "    skf = StratifiedKFold(n_splits=nb_splits)\n",
    "    i=1\n",
    "    y=Y\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        print('K-Fold : ',i)\n",
    "        print(datetime.datetime.now())\n",
    "        i=i+1\n",
    "        model.fit(X_train,y_train)\n",
    "        pred = model.predict_proba(X_test)\n",
    "        pred = pd.DataFrame(pred) #proba\n",
    "        pred = pred[1] #proba\n",
    "        prediction = pd.DataFrame()\n",
    "        prediction['target']=pred\n",
    "\n",
    "        treshold =np.arange(0.42,0.56,0.001)\n",
    "        listDic = {}\n",
    "        ensemble_pred = prediction\n",
    "        for each in treshold:\n",
    "            newPred = np.where(ensemble_pred['target'] > each, 1,0)\n",
    "            newPred = newPred.astype(int)\n",
    "            score = f1_score(newPred,y_test.astype(int))\n",
    "            listDic[each]=score\n",
    "\n",
    "        listKeyValue = []    \n",
    "        listKeyValue.append(max(listDic.items(), key=lambda x:x[1]))\n",
    "\n",
    "        listTreshold.append([item[0] for item in listKeyValue])\n",
    "        listScore.append([item[1] for item in listKeyValue])\n",
    "\n",
    "        #print(max(listDic.items(), key=lambda x:x[1]))\n",
    "\n",
    "    print(np.mean(listTreshold))\n",
    "    print(np.mean(listScore))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Code pour regarder les trajectoires test données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = pd.read_csv('LGBM11_44.csv')\n",
    "# tr = test.loc[test.x_exit.isnull()]\n",
    "# tr = tr.reset_index(drop=True)\n",
    "# tr['city_center'] = np.NaN\n",
    "# tr['city_center'][(tr.duree==0)]=0\n",
    "# tr['city_center'][(tr.duree==0)&(tr.x_entry>=3750901.5068) & (tr.x_entry<=3770901.5068)&(tr.y_entry>=(-19268905.6133)) & (tr.y_entry<=(-19208905.6133))]=1\n",
    "# tr['target'] = pred.target\n",
    "# tr.loc[tr.duree==0][(tr.target != tr.city_center)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y=train\n",
    "# Y = Y.groupby('hash')['city_center'].apply(list)\n",
    "# for i in range (Y.shape[0]):\n",
    "#     Y[i]=Y[i][-1]\n",
    "\n",
    "# Y=pd.DataFrame(Y)\n",
    "# Y = pd.DataFrame(Y.values)\n",
    "\n",
    "# Y.to_csv(\"Y.csv\",index=False)\n",
    "\n",
    "# train = train.drop(['city_center'],axis=1)\n",
    "# train = train.drop(['trajectory_id'],axis=1)\n",
    "# test = test.drop(['trajectory_id'],axis=1)\n",
    "\n",
    "\n",
    "def transformOnLine(df):\n",
    "    lesdataframes=[]\n",
    "\n",
    "    for vincent in df.columns[1:]:\n",
    "        print(vincent)\n",
    "        k=df\n",
    "        k = k.groupby('hash')[vincent].apply(list)\n",
    "\n",
    "        if (vincent == 'distCenter_exit') | (vincent == 'x_exit') | (vincent == 'y_exit') | (vincent == 'Ecart_dist'):\n",
    "            for i in range (k.shape[0]):\n",
    "                k[i].reverse()\n",
    "                k[i]=k[i][1:]      #x_exit y_exit\n",
    "                \n",
    "        elif (vincent == 'angle'):\n",
    "            for i in range (k.shape[0]):\n",
    "                try:\n",
    "                    k[i]=k[i][-2]\n",
    "                except(IndexError):\n",
    "                    #k[i]=-1\n",
    "                    k[i]=np.NaN\n",
    "                    \n",
    "#         elif (vincent == 'Ecart_dist'):\n",
    "#             for i in range (k.shape[0]):\n",
    "#                 k[i]=(np.cumsum(np.array(k[i][:-1]))).tolist()\n",
    "#                 k[i].reverse()\n",
    "#                  #k[i]=np.nanmean(np.array(k[i][1:]))\n",
    "        elif (vincent == 'vmin') | (vincent == 'vmax') | (vincent == 'vmean'):\n",
    "            for i in range (k.shape[0]):\n",
    "                k[i].reverse()\n",
    "                k[i]=np.nanmean(np.array(k[i]))\n",
    "#                 k[i]=max(k[i])\n",
    "#                 last=k[i][0]\n",
    "#                 if (last!=0):\n",
    "#                     if (len(k[i])>1):\n",
    "#                         k[i][0]=np.nanmean(np.array(k[i][1:]))\n",
    "#                     else:\n",
    "#                         k[i][0]=-1\n",
    "                \n",
    "        else :\n",
    "            for i in range (k.shape[0]):\n",
    "                k[i].reverse()\n",
    "\n",
    "\n",
    "        k=pd.DataFrame(k)\n",
    "\n",
    "\n",
    "        # expand df.time_entry into its own dataframe\n",
    "        gouz = k[vincent].apply(pd.Series)\n",
    "\n",
    "        # rename each variable is time_entry\n",
    "        gouz = gouz.rename(columns = lambda x : vincent + str(x))\n",
    "        \n",
    "        if(vincent == 'distCenter_exit') | (vincent == 'distCenter_entry') | (vincent == 'Ecart_dist'):\n",
    "            gouz = gouz.fillna(math.inf)\n",
    "        elif(vincent!='angle'):\n",
    "            gouz = gouz.fillna(0)\n",
    "\n",
    "#         if(vincent == 'Ecart_dist'):\n",
    "#             gouz = gouz.fillna(0)\n",
    "#         else:\n",
    "#             gouz = gouz.fillna(-1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        lesdataframes.append(gouz)\n",
    "\n",
    "    r = pd.concat(lesdataframes,axis=1)\n",
    "    r = r.reset_index()\n",
    "    r = r.drop(['hash'],axis=1)\n",
    "    #r.columns = np.arange(len(r.columns))\n",
    "    \n",
    "#     sup = r.vmax0.loc[r.vmax0>=0]\n",
    "#     r.vmax0.loc[r.vmax0<0] = sup.mean()\n",
    "#     sup = r.vmin0.loc[r.vmin0>=0]\n",
    "#     r.vmin0.loc[r.vmin0<0] = sup.mean()\n",
    "#     sup = r.vmean0.loc[r.vmean0>=0]\n",
    "#     r.vmean0.loc[r.vmean0<0] = sup.mean()\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.vmax = pd.read_csv('Vmax_comb_lgb.csv')\n",
    "# train.vmean = pd.read_csv('Vmean_comb_lgb.csv')\n",
    "# train.vmin = pd.read_csv('Vmin_comb_lgb.csv')\n",
    "# #tester avec combinée moins bon resultat en crossval avec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.vmax = pd.read_csv('Test_Vmax_comb_lgb.csv')\n",
    "# test.vmean = pd.read_csv('Test_Vmean_comb_lgb.csv')\n",
    "# test.vmin = pd.read_csv('Test_Vmin_comb_lgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmax\n",
      "vmin\n",
      "vmean\n",
      "x_entry\n",
      "y_entry\n",
      "x_exit\n",
      "y_exit\n",
      "duree\n",
      "distCenter_entry\n",
      "distCenter_exit\n",
      "Ecart_dist\n",
      "angle\n"
     ]
    }
   ],
   "source": [
    "X = transformOnLine(train)\n",
    "# X_test = transformOnLine(test)\n",
    "# X.to_csv(\"X.csv\",index=False)\n",
    "# X_test.to_csv(\"X_test.csv\",index=False)\n",
    "# X =pd.read_csv('X.csv')\n",
    "# X_test = pd.read_csv('X_test.csv')\n",
    "Y = pd.read_csv('Y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.vmean0 = pd.read_csv('TrainVmean0.csv',header=None)\n",
    "# X.vmin0 = pd.read_csv('TrainVmin0.csv',header=None)\n",
    "# X.vmax0 = pd.read_csv('TrainVmax0.csv',header=None)\n",
    "\n",
    "# X_test.vmean0 = pd.read_csv('TestVmean0.csv').vmean0\n",
    "# X_test.vmin0 = pd.read_csv('TestVmin0.csv').vmin0\n",
    "# X_test.vmax0 = pd.read_csv('TestVmax0.csv').vmax0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score 0.8839413141519666\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=1)\n",
    "clf = XGBClassifier(random_state=1)\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print('f1_score',f1_score(y_test.values.astype(int),pred.astype(int)))\n",
    "# #0.8783700809377617 baseline\n",
    "# #0.8795344106678721 distance au centre\n",
    "# #0.8818456969904631 distance au rectangle\n",
    "# #0.8833124215809285 rectangle + moments\n",
    "# #0.883853661320701 rectangle exit entry + ecart + moments \n",
    "# #0.8836334625028492 rectangle exit entry + ecart + moments + angle chaque traj\n",
    "# #0.88407120036513 pareil mais avec avant dernier angle\n",
    "\n",
    "# #0.883518994572979 rectangle exit entry + moments \n",
    "# #0.8827223935137604 angle du vecteur trajectoire par rapport au vecteur entrée->centre\n",
    "# #0.882212086659065 moyenne des angles d'avant\n",
    "# #0.8821448944666286 moment+ suppression de x,y pour coordonnées polaires par rapport au vecteur du centre au bord (angle entry,exit et distance entry,exit)\n",
    "# #0.8821030880495925 moment+ distance entry,exit par rapport au rectangle sans x,y ni angles\n",
    "# 0.8832000000000001 moment+ polaire pas bien\n",
    "\n",
    "#--------------\n",
    "# 0.8826248216833096 rectangle exit entry + ecart + angle[-2] car moment baisse le score sur vrai test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:   42.0s remaining:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:   42.8s remaining:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   42.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8860355175544568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "#clf = XGBClassifier(random_state=1)\n",
    "clf = LGBMClassifier(random_state=1)\n",
    "print(cross_val_score(clf, X, Y, cv=10,verbose=3, scoring='f1',n_jobs=-1).mean())\n",
    "\n",
    "#rectangle exit entry + ecart + angle[-2]\n",
    "#0.8832051335387705  --> baseline\n",
    "#0.8833877925293636 en remplacant par la moyenne de chaque utilisateur\n",
    "#0.8835050550850483 avec max pour les vitesses de chaque utilisateur\n",
    "\n",
    "#0.8835648861227721 en dropant vmax et vmin\n",
    "#0.8836510739023726 en prenant juste vmin0 vmax0 vmean0\n",
    "\n",
    "#tester avec le max\n",
    "#0.8838772443857035 avec les 3 vitesses calculées en regline sans vitesse celle de la dernière traj\n",
    "#--> on la calcule en faisant la moyenne de l'utilisateur\n",
    "#sans le comb\n",
    "#0.8836737715595501 avec le combiné en regLine\n",
    "#0.8837728831388306 avec le combiné en lgb\n",
    "\n",
    "#douille 0.8957555524288671"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Résultat pour LGBM ->\n",
    "avec les vitesses en régression : 0.8860016791383751\n",
    "normal : 0.8864894353898011 (XsansR enregistré)\n",
    "douille : 0.9047064951250308  et null en vrai\n",
    "normal version de base (Vincent) : 0.8864894353898011\n",
    "ecart dist à 0 au lieu de inf : 0.8864641364787811\n",
    "max des vitesses : 0.8866011325094734\n",
    "moyenne des vitesses : 0.8868870176810388\n",
    "vitesses et la derniere et une moyenne des autres : 0.8860355175544568"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc8AAAEWCAYAAAAASRzMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXl4VdXZvu8HYxUZpYJlKFIVEAEbARn6UwQRrLNWKqW1GlHb+hVbtKj42SJiFfSTKs6tCsERcUAU0UqVqMV5AMQBRaEV0eKAlUkRfH9/rHXCzsk+Q0JOsgPrvq59Ze+11/Ds0PpmTc+SmREIBAKBQCB/GtS1gEAgEAgE6hsheAYCgUAgUEVC8AwEAoFAoIqE4BkIBAKBQBUJwTMQCAQCgSoSgmcgEAgEAlUkBM9AIFCjSLpJ0p/qWkcgUEgU9nkGAslA0nJgd2BzJLmTma3cijoHAHeYWbutU1c/kVQKrDCzP9a1lsC2Reh5BgLJ4mgzaxy5qh04awJJRXXZ/tYgaYe61hDYdgnBMxCoB0jqK+lZSV9IWuh7lKl3p0p6S9IaSe9L+rVPbwQ8CrSRtNZfbSSVSvpzpPwASSsiz8slnS9pEbBOUpEvd7+kTyQtk/S7LFrL60/VLek8SaskfSTpOElHSHpH0ueS/jdSdpyk+yTd47/nVUk/jLzvIqnM/x7ekHRMWrs3SpojaR1wGvAL4Dz/7Q/7fGMkvefrf1PS8ZE6SiT9U9KVklb7bz088r6FpKmSVvr3D0beHSVpgdf2rKT98v4HDtQ7QvAMBBKOpLbAI8CfgRbAaOB+SS19llXAUUBT4FTgKkk9zGwdcDiwsho92eHAkUBz4FvgYWAh0BYYBIySdFiedX0P2NmXHQvcDJwE9AQOAsZK2jOS/1jgXv+tdwEPStpR0o5ex+NAK+As4E5JnSNlfw5cCjQBbgPuBK7w3360z/Oeb7cZcDFwh6TWkTr6AEuA3YArgFslyb+7HdgF6Oo1XAUgqQcwBfg18F3gr8BDknbK83cUqGeE4BkIJIsHfc/li0iv5iRgjpnNMbNvzWwu8DJwBICZPWJm75njKVxwOWgrdVxjZh+Y2QbgAKClmY03s41m9j4uAP4sz7q+AS41s2+A6bigNNnM1pjZG8AbQLSX9oqZ3efz/wUXePv6qzEw0et4EpiNC/QpZpnZfP97+ipOjJnda2YrfZ57gHeB3pEs/zKzm81sMzANaA3s7gPs4cBvzGy1mX3jf98AZwB/NbMXzGyzmU0DvvaaA9sg9XY+IxDYRjnOzP6RlrYH8FNJR0fSdgTmAfhhxYuATrg/iHcBXt9KHR+ktd9G0heRtB2AZ/Ks6zMfiAA2+J//ibzfgAuKldo2s2/9kHKb1Dsz+zaS91+4Hm2c7lgknQycA3TwSY1xAT3Fx5H21/tOZ2NcT/hzM1sdU+0ewCmSzoqkfSeiO7CNEYJnIJB8PgBuN7Mz0l/4YcH7gZNxva5vfI81NcwYt5x+HS7ApvheTJ5ouQ+AZWbWsTriq8H3UzeSGgDtgNRw8/clNYgE0PbAO5Gy6d9b4VnSHrhe8yDgOTPbLGkBW35f2fgAaCGpuZl9EfPuUjO7NI96AtsAYdg2EEg+dwBHSzpM0g6SdvYLcdrhejc7AZ8Am3wvdEik7H+A70pqFklbABzhF798DxiVo/0XgS/9IqKGXkM3SQfU2BdWpKekn/iVvqNww5/PAy/gAv95fg50AHA0big4E/8BovOpjXAB9RNwi62AbvmIMrOPcAuwbpC0q9fQ37++GfiNpD5yNJJ0pKQmeX5zoJ4RgmcgkHDM7APcIpr/xf1H/wPgXKCBma0BfgfMAFbjFsw8FCn7NnA38L6fR22DW/SyEFiOmx+9J0f7m3FBqhhYBnwK3IJbcFMIZgHDcN/zS+Anfn5xI3AMbt7xU+AG4GT/jZm4Fdg3NYdsZm8Ck4DncIG1OzC/Ctp+iZvDfRu3UGsUgJm9jJv3vM7rXgqUVKHeQD0jmCQEAoHEIGkcsLeZnVTXWgKBbISeZyAQCAQCVSQEz0AgEAgEqkgYtg0EAoFAoIqEnmcgEAgEAlUk7PPcRmnevLntvffedS2jAuvWraNRo0Z1LaMSSdSVRE2QTF1J1ATJ1JVETZAsXa+88sqnZtYyV74QPLdRdt99d15++eW6llGBsrIyBgwYUNcyKpFEXUnUBMnUlURNkExdSdQEydIl6V/55AvDtoFAIBAIVJEQPAOBQCAQqCIheAYCgUAgUEVC8AwEAoFAoIqE4BkIBAKBRPLBBx8wcOBAunTpQteuXZk8eTIAn3/+OYMHD6Zjx44MHjyY1avdKXGzZs1iv/32o7i4mF69evHPf/6zYNpC8NxKJI2TNLrAbfSU9LqkpZKuiZxqHwgEAtssRUVFTJo0ibfeeovnn3+e66+/njfffJOJEycyaNAg3n33XQYNGsTEiRMBGDRoEAsXLmTBggVMmTKF008/vWDaQvCsRfwRS9XhRuBXQEd//bjGRAUCgUBCad26NT169ACgSZMmdOnShQ8//JBZs2ZxyimnAHDKKafw4IMPAtC4cWNSfYt169ZRyH5GsOerBpIuxB0+/AHuiKhXgKOA0Wb2sqTdgJfNrIOkEuBIYGegkZkdIulc4ETcOYwzzewiX+9JuOOlvoM7u/B/gFbAPDPbx+cZDgwws19n09h+z72twYmTa/jLt44/dN/EpNeTt7U4ibqSqAmSqSuJmiCZupKoCSrrWj7xyEp5li9fTv/+/Vm8eDHt27fniy+2nEe+6667lg/dzpw5kwsuuIBVq1bxyCOP0K9fvyppkfSKmfXKlS95v8WEI6kn8DNgf9zv71Vc8MxGP2A/M/tc0hBc77E37vT6h/yBup/gzjD8f2b2jaQbgF8AbwIrInWtANpm0PYrXA+V3XZrydjum6r3kQVi94bu/yRJI4m6kqgJkqkriZogmbqSqAkq6yorK6vwfsOGDfz+97/n9NNP59VXX2XTpk0V8kSfd911V2666SYWLlzIyJEjmTRpUmFEm1m4qnDhDr8dH3n+CzAaKAN6+bTdgOX+vgSYGsl/Je4Q4gX+WgqcBowEVkbSlwDjgAOAf0TKHwQ8nEtnp06dLGnMmzevriXEkkRdSdRklkxdSdRklkxdSdRkll3Xxo0bbciQITZp0qTytE6dOtnKlSvNzGzlypWW6b93HTp0sE8++aRKWnCjhjljQZjzrB5xY92b2DKHvHPau3WRewETzKzYX3ub2a0+fVokvbOZjcP1NNtFyrfDBdlAIBDYpjEzTjvtNLp06cI555xTnn7MMccwbdo0AKZNm8axxx4LwNKlS1OdDF599VU2btzId7/73YJoC8Gz6jwNHC+poaQmwNE+fTnQ098PzVL+78AISY0BJLWV1Ap4Ahjq75HUQtIeZvYRsEZSX7/K9mRgVo1/VSAQCCSM+fPnc/vtt/Pkk09SXFxMcXExc+bMYcyYMcydO5eOHTsyd+5cxowZA8D9999Pt27dKC4u5re//S333HNPwRYNhTnPKmJmr0q6Bze0+i/gGf/qSmCGpF8CT2Yp/7ikLsBz/h91LXCSmb0p6Y/A45IaAN8Av/VtnAmUAg2BR/0VCAQC2zQHHnhgeU8ynSeeeKJS2vnnn8/5559faFlACJ7VwswuBS6NebVf5P6PPm8pLvBFy08GKi2FNbN7gHti0l8GulVbcGC75aqrruKWW25BEt27d2fq1Kn85je/4amnnqJZs2YAlJaWUlxcXMdKA4H6RQiegcA2yocffsg111zDm2++ScOGDTnxxBOZPn06AP/3f//H0KHZZhcCgUA2am3OM+XEI2m8pEOz5DtO0r5paaMlvS1psaSFkk6upoZiSUdUp2xNIKlEUptqlPuBpBckvSvpHknfKYS+wLbHpk2b2LBhA5s2bWL9+vW0aVPl//kFAoEYar3naWZjc2Q5DpiN29+IpN8Ag4HeZvalpGY+T3UoBnoBc/ItIKnIzGpqY1QJsJiY1bKSdjCzzRnKXQ5cZWbTJd2E29pyY7aGNnyzmQ5jHtlKuTXLH7pvoiRhmiCZurZGU2qDedu2bRk9ejTt27enYcOGDBkyhCFDhnDXXXdx4YUXMn78+HJrs5122qkm5QcC2zwFdRjK4MTTDZhtZvdJmggcg9vm8TjwAC5w/tdfJwDzgIFm9l5M/T1x+ywbA58CJWb2kaQynEPPQKA5Lti8gNtT2RD4EJjg27oW6I77Q2Kcmc2KcwXK8H2VnIIkdcAt6Pkn8CPf1rG+vlL/vAFnnPAWMAUY4sucYGY9fN0dgem4YP8J8D0z2ySpn9d5WIyeqElCz7FX3xwnu87YvSH8Z0Ndq6hMEnVtjabubd1c5po1a7jooosYO3YsjRs3Zty4cRx88MH06NGDFi1a8M033zBp0iTatGlTbnWWi7Vr19K4cePqCSsQSdQEydSVRE2QLF0DBw7My2GokGYCPYHXgV2AprjANRoXQIYCLXBGAKkA3tz/LAWG+vsmwOoM9e8IPAu09M/DgCn+vgyY5O+PwJsM4Hp+10XquAy30hVckH0HaOTzrQBaZPm+IcDfcPszG+ACcX+gA+6PgWKfb0akjTK8kYJ/Xg6cF3meFyl3GXAWznBhaSTP94HFuX7/wSQhf5KoqyY0zZgxw0aMGFH+PG3aNDvzzDMrtXPkkUfWqq6aJomazJKpK4mazJKlizxNEgo5bHsQrje2HkDSQ2nvvwS+Am6R9Agu+KQj4g0JADrjerFz/ZaPHYCPIu8f8D9fwQW0OIYAx0RORdkZaO/v55rZ5xnKpcoOAV7zz41xtnv/BpaZ2YI82oeKq2tvAU6VdA7uj4HexM9LB0PiQE7at2/P888/z/r162nYsCFPPPEEvXr14qOPPqJ169aYGQ8++CDduoWF3IFAVSn0nGfG/8ibG4LsDQzCecWOBA5Jy/OlpHWS9jSz99OqEPCGmWVy/f3a/9xM5u8Ubqh0SYVEqQ8VXYEylZ1gZn9NK9sh0naq/YZZ6om2cz9wEW6f6Ctm9pk3RmgemXsNDkOBvOjTpw9Dhw6lR48eFBUVsf/++/OrX/2Kww8/nE8++QQzo7i4mJtuuqmupQYC9Y5CBs+ngVI/r1mEc+IpDzTeYWcXM5sj6XncsC7AGtxwbYoJwPWShvlg2hQXbEuBlpL6mdlzknYEOpnZG1k0pdf9d+AsSWeZmUna38xey1A2nb8Dl0i608zWSmqLMzbIRnr7FTCzryT9HbcY6DSfZpLm4Ya6pwOnEByGAnly8cUXc/HFF1dIe/LJjB4egUAgTwq2VcXMXsUNSS7A9aieScvSBJgtaRHwFHC2T58OnCvpNUl74QLJPOAlSYt93vVmthEXUC6XtNC386McsuYB+0paIGkYcAlu7nSRr/uSKnzf48BdOKeg14H7yBIYPaXATb79TL3RO3E99scjaecD50haCnwXuDVfnYFAIBCoeQo6bGuZnXhS9I4pMx/YNy35Cn+l512AW6STnj4gcv8pfs7Rz2EekJa90rmYFuMKFIdlcAoi4gZkZldG7u/H/SGRokNM2QNxC5/Kt634IetKv6vA1rN582bOOOMMOnfuzOzZsznooINYs2YNAKtWraJ3797lB+0GAoFAiuAwVIv4LTCPm1nsnKWkmcBepM39SvoBrkfeAnd+6C99zzuwlUyePJn27duXPz/zzJYBkhNOOKH8tIZAIBCIEk5VyYGk7n6YNXq9UM3qSoBYixdvknC8me3ne8tRUiYJHYHV+PnQwNaxYsUKHnnkEY48svKp9WvWrOHJJ5/kuOOq68cRCAS2ZULPMw1JB+DmFHvjtr9MB4aZ2eKYvFU1SegF3Ckp1iRBUiaThEOAn/tmp+EOyQ4OQ9Ug5b4DMGrUKK644ooKvc0UM2fOZNCgQTRt2rQ25QUCgXpCCJ5pmNlLfk/qn3FbTO7IEDiH4PZ19sZtW3lIUn/cPs+OwHAzO0PSDNx2mDskjQRGmzslJXXO3FdmdqB/PlRSsZ/LPRU37/pd4AvbYhG4Amgbpz3NYYix3WvKVbBm2L2hC6B1SVlZGQDPPfcc33zzDWvWrGHDhg189tln5e8Arr/+eo444ogKabXJ2rVr66ztbCRRVxI1QTJ1JVETJFdXVvJxUtjeLuA7wEKcpd8OGfJciXMIWuCvpbjh1A7Au5F85wN/tMwOQ3tEnn+BW4C0A/AeLnC2pLLD0Ou5viE4DGVnzJgx1rZtW9tjjz1s1113tYYNG9ovfvELMzP79NNPrUWLFrZhw4Y605ek31WUJOpKoiazZOpKoiazZOkiT4ehMOcZTwucY1ATnOtQHCmThGJ/7W1mqS0k6SYJ2Xr46SYJhwNH4U0ScJ69zSWl6ggmCTXAhAkTWLFiBcuXL2fs2LEccsgh3HHHHQDce++9HHXUUey8c6Z/+kAgsL0Tgmc8fwP+hNtzeXmGPH8HRnizByS1ldQqR705TRJ8vTcCU32a4fanpg5fDCYJBWb69OkMHz68rmUEAoEEE+Y80/BnhW4ys7sk7QA8K+kQM6tgy2Jmj0vqgjNJAFgLnITraWaiFGeSkFowFMedwE+obJIwXdKfcV66wSShBikuLmbUqFHlz/Vu7iUQCNQ6oeeZhpndZmY/8febzaxPeuCM5J1sZt391c/M3jOz5WZWwSTBzMb5+/vNrLMf5t1gZh2s8raUWJMEM+vth4Z/amZfU8/54IMPGDhwIF26dKFr165Mnuy8JsaNG0fbtm0pLi6muLiYOXPyPno1EAgEao3Q80wQmUwStkWKioqYNGkSPXr0YM2aNfTs2ZPBgwcDcPbZZzN69OgcNQQCgUDdEYJnDiR1B25PS/7azPpUo64SsjgMmdnxGcptcw5DrVu3pnXr1gA0adKELl268OGHH9axqkAgEMiPEDxzYGavA8U1VF0JsJiY1bLeYSjTfGnKYWi6pJtwW2LqnUlC6Y8bxaYvX76c1157jT59+jB//nyuu+46brvtNnr16sWkSZPYdddda1lpIBAIZEduMWcghaRLgE/Nmb4j6VLgP2Z2TUzeqjoMlfrnWIchnJlCnMPQJ8D3zJ2B2g8YZ2aHxeiJmiT0HHv1zTXwG6k5ftBsBxo3blwhbcOGDfz+97/npJNOon///nz++ec0a9YMSUyZMoXPPvuM888/v6C61q5dW0lXXZNETZBMXUnUBMnUlURNkCxdAwcOfMXMeuXMmM9m0O3pwpkcvOrvG+DNCmLyDcFtaZHPNxt3wksHYBNQ7PPNAE6yzCYJ50We50XKXQacBexGZZOExbm+oz6YJGzcuNGGDBlikyZNis2/bNky69q1a63rSgJJ1GSWTF1J1GSWTF1J1GSWLF0Ek4TqYWbLgc8k7Y8LkK+ZMytIZ0jqPW4ech+cLR/AMnMWewCvEH/0WIp7Ive3AKf6LTLDcOeFKk5mXh+TYMyM0047jS5dunDOOeeUp3/00Ufl9zNnzqRbt25xxQOBQKBOCXOe8dyCm5/8Hm5YNY6Uw9BfKyS6Ydt0h6FMB19DZYehi4An8Q5DcptIm0sqMudvu004DM2fP5/bb7+d7t27U1zsppQvu+wy7r77bhYsWIAkOnTowF//+tccNQUCgUDtE4JnPDOB8cCObDnNJJ2/A5dIutPM1kpqC3yTo96cDkOSUg5Dp/k0k5RyGJrONuIwdOCBB6aGoStwxBFH1IGaQCAQqBph2DYGc9tA5gEzLMMKWDN7HDes+pyk14H7yBIYPaU4h6EFkjL1Ru/EDcumOwydI2kpziy+XjkMpQwRTjnllAqGCOeeey777LMP++23H8cffzxffPFFHSsNBAKB/Ag9zxgkNQD6Aj/Nls/citzJMa8qOAxF7u/HDc2m6BBTNtZhCHf0Wb0kZYjw5Zdf0rNnz3JDhMGDBzNhwgSKioo4//zzmTBhApdfnslKOBAIBJJDrfU8JY2TNFrSeEmHZsl3nKR909JGS3pb0mJJC73/bHU0FEvKOi7o214KPGFm71annSx1l0hqk+X9TOBk0gKypDslLfHfP0XSjjWpq9C0bt2aHj16ABUNEYYMGUJRkfv7rW/fvqxYsaIuZQYCgUDe1PqwrZmNNbN/ZMlyHFAePCX9BhgM9DbnGduf+BWo+VAMZA2eZvamme1pZn/w7Rf7Ydbo9UI12y8BYoOnN0k43sz2s8p+t3fiVvN2xy0+Or2a7dc5UUOEKFOmTOHwww+vI1WBQCBQNQo6bCvpQlxP6gPcRv9XJJUCs83sPkkTgWNw+yIfBx7wzwdL+iNwAvC/wEAz+xLAzP4LTPP19wT+gjt781OgxMw+klSGO8h6INAct/jmBdwioIaSDgQm4PZmXosLSkU484FZ3kbvSNxZno3MLNZhqBomCb2AOyOnqlQwSZBUySTBzHqa2ZxImy/iVtxmJQkOQ8snHlnhecOGDZxwwglcffXVNG3atDz90ksvpaioiF/84he1LTEQCASqRcEchnxgKwX64ALTq8BNuPnA2bjtGM8B+/gVpc3N7Iu04NoE+LeZVfJn80OXTwHHmtknkoYBh5nZCB88XzGzP/hh2nPM7FAfFHuZ2Uhfx2XAm2Z2h6TmwIvA/ri5zj8D+5nZ5xm+bwhuBeyvcT3hh4ArgH/jhn17mdkCSTOAh3wbZcBoM3vZ17EcuMHMrvDP84CzfbnLgI/M7Nq0b34B+L2ZPROjKVEOQ93bNiu/37RpE+eddx59+/blxBNPLE9/7LHHePjhh5k0aVKdHT6dJHeTFEnUBMnUlURNkExdSdQEydKVr8NQIXueB+F6Y+sBJD2U9v5L4CvgFkmP4AJqOiKzIUBnXCCe68/T3AH4KPL+Af8zm0nBEOAYSakjPHYG2vv7uZkCZ6RsyiQBXO+3Iy54bq1Jwjk4k4T0RUI3AE/HBU4AM/sbzvWIzp0721m/ODZLs7WHmXHKKaew5557csMNN5SnP/bYYzz00EM89dRTtGzZss70lZWVMWDAgDprP44kaoJk6kqiJkimriRqguTqykahV9tm7Naa82ntDQwCfgaMJO0oLjP7UtI6SXv6FadRBLxhZpkOlU4ZFWwm83cK5ye7pEKi1IeK5gWZyhbcJCFS70VAS1xPt16RMkTYc889Kxgi/O53v+Prr78uP4qsb9++3HTTTXUpNRAIBPKikMHzaaDUz2sWAUcD5YFGUmNgFzObI+l53FAnVDYSmABcL2mYD6ZNccG2FGgpqZ+ZPeeHNDuZ2RtZNKXX/XfgLEln+aHj/c3stQxl06kVkwQASacDhwGDzOzbPPUlhpQhQvpfl8EQIRAI1FcKttrWzF7FDUkuwPWo0ocamwCzJS3CzV2e7dOnA+dKek3SXrhAMg94SdJin3e9NzIYClwuaaFv50c5ZM0D9vUrZocBl+BchBb5ui+pwvfVpknCTcDuvq0FksbmqzMQCAQCNU9Bh23N7FLg0ixZKm38N7P5RLaqeK7wV3reBbitK+npAyL3n+LnHP0c5gFp2SsNg5pZKS7QZaUWTRISa2YxYsQIZs+eTatWrVi8eHF5+rXXXst1111HUVERRx55JFdcUemfLxAIBOotif2P8vaIN0nYi7S53yRTUlLCyJEjOfnkLb4V8+bNY9asWSxatIiddtqJVatW1aHCQCAQqHmCw1DuMt1ryiQhl8NQJpMESSMlLZVkknarTtuFon///rRo0aJC2o033siYMWPYaaedAGjVqlVdSAsEAoGCUes9TzPLNV93HG7byptQyWHoS0nNfJ7qUIwzKpiTK2OEtzKZJFSDEmAxMUeKeYehWBN6YD7ud1KWb0OFNklIN0CI8s477/DMM89w4YUXsvPOO3PllVdywAHpo+WBQCBQfymYSQLEOwzhTRKyOAzNBv7rrxNwi3wGmtl7MfVX1WFoKW7byIdUzWEodhi1Gg5Dpf451mEIt22mksNQpL3lOPOFdPu+1PtaM0mIGiB8/PHHXHDBBUydOhWAU089lf3335+zzjqLt99+m/Hjx3PXXXexbt26xGyEjpKkDdopkqgJkqkriZogmbqSqAmSpStfkwTMrCAX0BN4HdgFaIoLXKNxAWQo0AJYwpYA3tz/LAWG+vsmwOoM9e8IPAu09M/DcAttwPXQJvn7I4B/+PsS4LpIHZcBJ6XaB94BGvl8K4AWWb5vCM6QQLjh79m4xUsdcH8MFPt8MyJtlOGCX6qO5cB5ked5kXKXAWeltbkc2C2f33+nTp2stli2bJl17dq1/Pmwww6zefPmlT/vueeetmrVqgppSSKJupKoySyZupKoySyZupKoySxZuoCXLY//xhZyzrPcYcicL202h6GfAOtj6sjXYWgB8Ecqer7m6zA0xpcvo/oOQ6/ijNs7+nfLbOschnbA/TFwV5ZyieW4447jySefBNwQ7saNG9ltt0RN1QYCgcBWERyG6onDUFIZPnw4ZWVlfPrpp7Rr146LL76YESNGMGLECLp168Z3vvMdpk2bhrdQDAQCgW2C4DBUDxyGkszdd98dm37HHXfUspJAIBCoPYLDUD1wGJL0O0krcMPSiyTdkq/OQjNixAhatWpFt27dKqRfe+21dO7cma5du3LeeefVkbpAIBAoDMFhqH44DF0DXJNLT10QTBICgcD2SK3t85Q0DliLW3n7tJn9I0O+44B3zOzNSNpo4HTcKtbNuJW0t1VDQzHQxiKHS9cmfgvM42ZWaZ+nfx/rMCTpVtz+VOFWBJeY2drCqs2P/v37s3z58gppwSQhEAhs69Saw1AKMxubKXB6jiPS80wzSeiG62lWd/VJMW7rSt54V6IacRjCbYGJdRjyJgmxDkO4A7J/aGb74c4LHVnN9muFlElCnz59OPjgg3nppZfqWlIgEAjUKAXtecaZJEgqJbtJwjHAwZL+iDNJ+F+cScKXAGb2X2Car7+qJgnjgYaSDqRqJgmxDkPVMEnoBdwpKdYkQVKsSULq2+WWrDYkyyrmFHXpMLRp0yZWr17N888/z0svvcSJJ57I+++nL5YOBAKB+kvBgqcPbD8D9vftvIrb85h63wI4HtjHr3RtbmZfSHqILcG1CdDE4t2FdsQFvmPN7BO/AOhSYETq28yst/eyvcjMDvVHefUys5G+jsvuiaNNAAAgAElEQVSAJ81shKTmwIuSUr3ifsB+mfZ6ShqC29fZG9cTfkhSf1zPsCMw3MzOkDQDtx3mDkkjgdFm9rKvA+ArMzvQPx8qqdjP5Z5KZN5V0lRcr/lN4A8ZNJU7DLVs2ZIZP24Ul61GKCsrK7//+OOPWbduXXnaLrvswp577slTTz0FwMaNG5k1axZFRUUVyiWFtWvXJk5XEjVBMnUlURMkU1cSNUFydWWjkD3PcpMEAB8Uo0RNEh7B9QLTydckAWAH4KPI+3xNEo7xc6pQfZMEcL3fjrjgubUmCefgTBLKF1SZWco84Vr/bmp6RWb2N5zrEZ07d7bowdOFZPny5TRq1Kj8oOsRI0awcuVKBgwYwDvvvEODBg049thjeeqpp6gtTVUh/ZDuJJBETZBMXUnUBMnUlURNkFxd2QgmCfXIJMHMNku6BziXmOBZFwSThEAgsD0STBISbpLg5zn3MrOl/v5o4O08NRacYJIQCAS2R4JJQvJNEgRM8228DrTGLXwKBAKBQB0RTBISbpJgZt8C/y+XltpixIgRzJ49m1atWrF48WIA/vSnPzFr1iwaNGhAq1atKC0tpU2bjGd+BwKBQL2n1vd5BjLjTRJOJj4gJ4KSkhIee+yxCmnnnnsuixYtYsGCBRx11FGMHx86xoFAYNum1oKnpHGSRksaL+nQLPmOk7RvWtpoSW9LWixpoaSTM5XPoaHYb12pSpnuNWWSIKlEUsYuWRaThFT5ayXVqbNQ//79adGiRYW0pk2blt+vW7cuLA4KBALbPLVmz5fCzMbmyHIcbtvKm1DJYehLSc18nupQjDMqqIo931uZTBKqQQmwGKhkz+cdhjZXKrHlfS+c4UNe1KRJQjZDhBQXXnght912G82aNWPevHk10m4gEAgkFZnlNKupfuUxDkO4+cBsDkOzgf/66wTcIp+BGYwSquowtBS3beRDquYwVGELTaT9qjoMlfrnWIch3LaZSg5Dfn/nP4CfA++aWeMMespNEnbbrWXPsVffHJetynRv26zC88cff8wFF1zA1KmVd8vceeedbNy4kVNPPbXSu7Vr19K4caz0OiWJupKoCZKpK4maIJm6kqgJkqVr4MCBr5hZr5wZzawgF9ATtzp0F5wZ/FJgNC6ADAVaAEvYEsCb+5+lwFB/3wRYnaH+HYFngZb+eRhuoQ1AGc48Hpwrzz/8fQlwXaSOy4CTUu3jTNcb+XwrgBZZvm8IzpBAuOHv2bjFSx1wfwwU+3wzIm2U4RyOUnUsB86LPM+LlLsMOMvf/x7nbwuwNp/ff6dOnaxQLFu2zLp27Rr7bvny5RnfzZs3r2CatoYk6kqiJrNk6kqiJrNk6kqiJrNk6QJetjz+GxschhLuMOTnSH8KDMhSR53y7rvv0rFjRwAeeugh9tlnnzpWFAgEAoUlOAwl3GFI0pHA3sBS/0fCLpKWmtneOfQVhDhHoTlz5rBkyRIaNGjAHnvswU033VQX0gKBQKDWCA5DCXcYMrNHgO+l8khaW1eBE+IdhU477bQ6UBIIBAJ1R3AYSr7DUCIYMWIErVq1olu3cv8Hzj33XPbZZx/2228/jj/+eL744os6VBgIBAK1R3AYSrjDUEybdbIkraSkhJEjR3LyyVu22A4ePJgJEyZQVFTE+eefz4QJE7j88svrQl4gEAjUKsFhKAFIaiPpPu8w9Cvgjcg7SbpG0lJJiyT1qAuNceYIQ4YMoajI/f3Vt29fVqxYURfSAoFAoNapdZOE+oak7sDtaclfm1mfmmrDzFbihqDxe0wPxA1fAxyOW8XbEeiDG8bO2XZNmSTkY5AAMGXKFIYNG7bV7QUCgUB9oKAmCdsakg4AbsUNN+8AvAgMM7PFMXnjDBRiywNrcVt1elDZyOEQoMzM7vb1LgEGmNlHpFEIk4SoQUImc4Q77riDJUuWMH78+KzWfEnaCB0libqSqAmSqSuJmiCZupKoCZKlq85NErbVC/gzcCVwPXBBhjyxBgqZyuPmPhdbvJHDbODAyPMTRIwWMl2FMEmIM0coLS21vn372rp163KWT9JG6ChJ1JVETWbJ1JVETWbJ1JVETWbJ0kUCTBK2VcYDL+EMHn6XIU8mA4Wn8ywfJa4rl4jhgscee4zLL7+cp556il122aWu5QQCgUCtEYJn1WmBC4Y74hyJ4swUYg0UqlA+ygrg+5HndsQYyxeaOHOECRMm8PXXXzN48GDALRoKBgmBQGB7IATPqvM34E/AD4DLcc5I6cQaKJjZqjzKpxspPASMlDQdt1DovxYz31logjlCIBAIbKHKwVPSrsD3zWxRAfQkGn+O6CYzu8ufdPKspEPM7MloPjN7XFIXnIECuAVBJ0n6cVx5IGo9OA8YI2kBbsHQDJy5/VJgPVD5uJJAIBAI1Cp57fOUVCapqaQWwEJgqqS/FFZa8jCz28zsJ/5+s5n1SQ+ckbyTzay7v/qZ2XuZypvZcjPr5tM/N7MDzKzYzO7xc9i/NbO9fF0v194XO+Lche699166du1KgwYNePnlWpcUCAQCdUq+JgnNzOxL4CfAVDPrCRxaOFmBJFFSUsJjjz1WIa1bt2488MAD9O9fyeApEAgEtnnyDZ5Fklrj9i3GHR2WE0njJI2WNF5SxsAr6ThJ+6aljZb0tqTFkhb64dPqaCiWdER1ymaor7v3qY1eL2TJX+KPGKtqO5J0qaR3JL0lKZ9VujVGnLtQly5d6Ny5c23KCAQCgcSQ75zneNwimPlm9pKkPYF3q9OgmY3NkeU4XIB+E0DSb4DBQG9zp6o083mqQzHQC5iTbwFJRWa2Ke6dmb3u68yXEmAxMatlJe1gGfxsfbnvA/uY2beSWuVqaGsdhvJ1FgoEAoHtkYI6DEm6EDgZ+AD4BHcwdDdgtpnd548rOwbYhDtF5AFc4Pyvv07ALaAZaGbvxdTfE/gLbuvHp0CJmX0kqQx4ARgINMcd7/UCld17ZgPXAt1xf0iMM7NZ3iLvSNxWkkZmVuGc0Uj7cS5CHYBHgX/iTnn5EDjW11fqnzcA/YC3gCm4PaGP4s4W7eHr7ghMN7Oekl4Efm5mS8lCTToMRZ2FILO70KhRozjzzDPz6oUmyUUkShJ1JVETJFNXEjVBMnUlURMkS1eNOgwBnXDONikXnP2AP+Yo0xN4HdgFaIoLXKNxAWQobr/jErYE8Ob+Zykw1N83AVZnqH9H4FmgpX8ehjuNBKAMmOTvjwD+YfHuPZcBJ6XaB94BGvl8K4AWWb4v1kUI5xa0CSj2+WZE2igj4g4ELAfOizzPi5S7DDjL338GXAi8jAuyHXP9m9W0w1Ccu5CZ2cEHH2wvvfRSXnUkyUUkShJ1JVGTWTJ1JVGTWTJ1JVGTWbJ0kafDUL5znjcDF+APeza3TeVnOcochOuNrTe32OihtPdf4lx2bpH0E9w2jHREZjedzrhe7Fy/reOPOAOBFA/4n68Qf/QXuACY2hZShutptvfv5po7wiwTURehV4F9cC5CAMvMHZeWq31wZ56muAU41W9jGYY7LxRcz/Yrc38N3YzrrQYCgUCgjsg3eO5iZi+mpcXOA6aRcUzY3Dxib9z5lscBj8Xk+RJY5+dY0xHwhrktHcXmtnEMibz/2v/cTOa5XeGGSlN1tDezt/y7XM4/KRehVNm9zezWtLZztZ/ezv24U1SOAl4xs898+gq2nAM6E9fzrzWGDx9Ov379WLJkCe3atePWW29l5syZtGvXjueee44jjzySww47rDYlBQKBQJ2S74KhTyXthQ+GkoYCuVxungZK/bxmEXA0UG5XJ6kxLijPkfQ8blgXKjvsTACulzTM3IKhprhebynQUlI/M3tO0o5AJzN7g8yk1/134CxJZ5mZSdrfzF7LUDadWBehHGXS26+AmX0l6e+4Y8ei9j0P4k5XmQIcjBterjXi3IUAjj/++NqUEQgEAokh357nb3GBbx9JHwKjgN9kK2Bmr+KGJBfgek3PpGVpAsyWtAh4Cjjbp08HzpX0mg/YN+LmAl+StNjnXW9mG3Fzp5dLWujb+VGO75gH7Ou3lAwDLsHNnS7ydV+So3z0+x7HDas+J+l14D6yBEZPKXCTb79hhjx34v5IeTySNhE4wbczATg9X51bQ5w5wueff87gwYPp2LEjgwcPZvXq1bUhJRAIBBJFzp6npAa4RS6HSmoENDCzNflUbmaXApdmydI7psx8YN+05Cv8lZ53AW6RTnr6gMj9p/g5Rz+HeUBa9l/HlC/FBbqsmNlkYHLMq26RPFdG7u9ny/ArxM+FHohb+FS+bcXMvsCt1q1VSkpKGDlyJCefvGVb7cSJExk0aBBjxoxh4sSJTJw4kcsvv7y2pQUCgUCdkrPnaWbf4s3LzWxdvoGzKmyLBgpVbLuNpPskzcRtNXkj8k6SrpG0VNIiST1qS1ecOcKsWbM45ZRTADjllFN48MEHa0tOIBAIJIZ85zznShqNG4YtX+CSYzVqlbEEGihI6g7cnpb3azPrk81AoSqY2UrcEDR+j+mBuOFrcAuIOvqrD24Yu0+uOrfGJCGbQcJ//vMfWrduDUDr1q1ZtWpVtdoIBAKB+kxeJgmSlsUkm5nFrYLNr+Ht00DhAOBW3HD1DsCLuC0pa317PWJ0HAKUmdndvt4lwACLOZaspkwSogYJ6eYIRx11FLNnb3FoPProo3n44YfzqjdJG6GjJFFXEjVBMnUlURMkU1cSNUGydNWoSUJNX2ynBgr+3Z+BK4HrgQt8Wge2GFCk65gNHBh5foKI0UKmq6ZMEtLNETp16mQrV640M7OVK1daVdpJ0kboKEnUlURNZsnUlURNZsnUlURNZsnSRZ4mCXkN22aaRzSz2/IpH0O5gYKvP5uBwiPEm9Hna6AArpcX7anla6BwjB+uhuobKIDr/XbEbd8ZD7yE+758DN4Vk1Y4T8UcHHPMMUybNo0xY8Ywbdo0jj322LqSEggEAnVGvnOe0RWqOwODcK461Q2ekMNAQVJv387PcAuWDknL86WkdZL2NLP306pIGSj0y9BEVQwUllRIlPqQv4HCX2PetcAF0x1xv8tcda3AmcKnaEeMsXwhGD58OGVlZXz66ae0a9eOiy++mDFjxnDiiSdy66230r59e+69997akBIIBAKJIq/gaWZnRZ/9wpz0RTRVYbs0UDCzVbjh3D8BPwAux69kzqLjIWCkpOm4hUL/tZj5zkKQyRzhiSeeqI3mA4FAILHk2/NMZz1bfFyrjJm9KilloPAv4g0UZknaGdeLixoo3OzPsxyKW3naGGeg8A3O4WeSmW30LkjX+EBfBFxNZAtIDPPY4nM7AWeYcDXOQEE4E/ej8vy+xyV1wRkogFsQdJKkHwObzOwu71/7rKRDgGjPOV3HDNzc7FLc7/3UfDQEAoFAoHDkO+f5MFuGWRvgTAy2arzOtk8DhffwQ93mTBCiW066ZdHx21ztFYIRI0Ywe/ZsWrVqxeLFiwHnMDRs2DCWL19Ohw4dmDFjBrvuumtdyAsEAoE6I197viuBSf6agFs5en7BVAUqIKmnpNe9UcI1vidccEpKSnjssYp+/SmHoXfffZdBgwYxceLE2pASCAQCiSLf4HmEmT3lr/lmtkLSdu/JJqm796mNXi8UoKkbcfs3U2YJPy5AG5UIDkOBQCAQT75znoOB9J7m4TFp2xT+D4R/mdkN/nkcbkHPMcB/cK5ED+D2rP4eZ27wc5+3JXATW7a3jDKz+X4V8dU+7wbgVDNb4s0XjsHtfd0Lt5XnPEmtgaZm9pyv9zaci9Kj2bQHh6FAIBAoHFmDp6Qzgf8B9vSnn6RoAswvpLCEMB0X6G7wzyfiTjj5IdAF+By32OcWM+st6ffAWbhTZyYDV5nZPyW1x63A7QK8jRv23uR9fC/DuSWBC8b747bSLJF0LbA7brtKihVA2zixaQ5DjO1ePefAsrKy8vuPP/6YdevWladt2rSpwvv052ysXbs277y1SRJ1JVETJFNXEjVBMnUlURMkV1dWsjkoAM1wC2ruBvaIXBnddba1C3gLaIMLmPOBATiThNT7p4H/5+8PAR7096twq4lT14e4Pzq+jzvQejGux/q2bXEWujlS76M4j9sD8C5IPv0g4OFcuoPDUP4kUVcSNZklU1cSNZklU1cSNZklSxd5OgxlnfM0s/+a2XIzG25m/8INMxrQ2Pemtgfuw22LGcYWs/avI++/jTx/y5befAOgn5kV+6utuRNpLgHmmVk33P7WnSN1RetNGTiswBkjpKg1k4Q4Ug5DQHAYCgQC2y15LRiSdLSkd4FluMOol5Njzm0bYjrOeGEoLpDmy+NEDBAkFfvbZrheKLjeZlbMGSKskdTXr7I9GZhVBR3VZvjw4fTr148lS5bQrl07br31VsaMGcPcuXPp2LEjc+fOZcyYMbUhJRAIBBJFvguG/gz0xQ0f7i9pIDC8cLKSg5m9IakJ8KG5U1k651n0dzj3o0W43/PTwG9we1KnSToHeDLPus7E7S1tiPujpVb+cAkOQ4FAIBBPvsHzGzP7TFIDSQ3MbN72tFXFzLpH7stwJ7OkngfEvTNnwDAspq7ngE6RpD/59FIi5gtmdlTk/mW8iUJtMXnyZG6++WbMjDPOOINRo0bVZvOBQCCQaPLd5/mF95t9BrhT0mTcOZuBbZDFixdz88038+KLL7Jw4UJmz57Nu+++W9eyAoFAIDHkGzyPxfmqjgIew9nMHV0oUTWJpM1pJgZbPUknqbmk/6limVLvt4ukWySl2wxG85ZIahN5HundhUzSbtVXnh9vvfUWffv2ZZdddqGoqIiDDz6YmTNnFrrZQCAQqDfke6rKOkl7AB3NbJqkXXBnZNYHNphZce5s+eEN3Zvj9r/ekCN7LGZ2eo4sJbitLKlVtfNxZ5qW5dtGdUwSUuYI3bp148ILL+Szzz6jYcOGzJkzh169ch+sHggEAtsLcttacmSSzsBtvm9hZntJ6gjcZGaDCi1wa5G01swax6QfgDMyaITbIjII+C7uqLVGPttIM3tW0gDgItyB2sXAIlxvfAluz+e5MfULuBa393MZ7nSYKWZ2n6QyYDTusOxbgV64LUBTgA9wc58f4rYG9TOzDb7O5UAvP58a961Rk4SeY6++Oc/fkqN722bl94888gizZs2iYcOG7LHHHuy000789rdb50+/du1aGjeu9E9R5yRRVxI1QTJ1JVETJFNXEjVBsnQNHDjwFTPL3VvIZzMobpP/d4DXImmv51O2ri/cfsmoWcEw/y3vAwf4PE1xvfBdgJ19Wkf8ZlmcMcI64Af+uQOwOEe7PwHm4nrobYAvgKH+XRkuYPakouFC8+j7mDqXA7vl8901ZZJgZnbBBRfY9ddfv9X1JGkjdJQk6kqiJrNk6kqiJrNk6kqiJrNk6SJPk4R8V9t+be6MTAAkFbHliLKkU2nYVlJ34CMzewnAzL706Y2A6/yezM1UXBX7opktq0K7/YG7zR09tlJS3LaU93HWh9cCj+D2hiaCVatW0apVK/7973/zwAMP8Nxzz9W1pEAgEEgM+QbPpyT9L9BQ0mDcfN/DhZNVcER88D8bZ/j+Q9xiqq8i79ZVo52sf2CY2WpJPwQOw53ZeSIwohrt1DgnnHACn332GTvuuCPXX399OLMzEAgEIuQbPMcAp+G8WH8NzAFuKZSoWuBtoI2kA8zsJW+CsAHn/rPCzL6VdAqZF0WtwfnUZuNp4Nf+FJRWwEDgrmgGv3J2o5ndL+k9tuzzzKf+gvLMM8/UZfOBQCCQaHKdqtLezP5tZt8CN/urvtFQ0oLI82NmNkbSMOBaSamjwQ7FrZ69X9JPgXlk6G2aM4yYL2kx8KjFLBjCmb8fgvuD4x2crWE6bYGpklJbhi7wP0uBmyRtAPoBZwDnAd8DFkmaY7lX7AYCgUCgQOTqeT4I9ACQdL+ZnZAjf+Iws9jeo5/v7JuW/C6wX+T5Ap+3jLRtImb28xztGhFv27R3AyKPPWLe3w/cH0m6xl+1RnAYCgQCgczkMklQ5H7PQgopFNuISYIkXSrpHUlvSfpd9dXnJjgMBQKBQHZyBU/LcF+f2GBbjgUrNrOJW1NZmkkCkrqnBecFkl7IVoeZnW5mb2bJUoLb3hJ9/j6wj5l1YcvRaAUhOAwFAoFAdnIN2/5Q0pe4HmhDf49/NjNrWlB1BaQGTBL28nOpc9O3wvj640wSUu/KyG6S0AvnIZya8zwT+Lmfe8bMVuX6vuAwFAgEAoUjL4eh+oykzbhFOykm4BbzvA0M86ttm+K8e78DfGtmX3kXpbvNrJcPno8A3cxsmaQOwGxzB1pnavcnuKD3Y2B34E3gdKvoMGTARDMb7Ms0N7MvUu/NnaaCpM+AvwDHA58AvzOzSuOowWGoeiRRVxI1QTJ1JVETJFNXEjVBsnTVqMNQfb6AtTFp3YH5MenNcD3P13FuROtti8PQvEi+DuR2GLoaGBF5foDKDkO74kz2r8UF2QbR99FvAP5gW5yLnsn13cFhKH+SqCuJmsySqSuJmsySqSuJmsySpYs8HYbyPVVlWyMfk4ReuJ5oioKYJPi2ynAmCZn2zq5gy+rbmVRcEVwQVq1yI8Mph6Hhw7eLs88DgUAgL7bX4FlukgAgqYm3HGyGs+37FvglW2+S8DNJO0hqjTNJqIA3SWhgbmvKn9iybSW9/gdxc6cAB+P2jRaUE044gX333Zejjz46OAwFAoFAGvk6DNVntgWThIm4BURn44ZwC26QEByGAoFAIDPbfPC0bcMkYQNwZLb2apKrrrqKW265BUl0796dqVOnsvPOO9dW84FAIJB4ttdh20AGPvzwQ6655hpefvllFi9ezObNm5k+vaDbSgOBQKDeUWvBU9I4SaMljZd0aJZ8x6W77/hyb0taLGmhpJOrqaFY0hHVKZulzrxNEtKdg6rQxiBJr/q6/ylp761XnplNmzaxYcMGNm3axPr162nTpsqSA4FAYJum1odtzWxsjizHAbNx+yKR9BtgMNDbzL6U1MznqQ7FuFW0c/ItIKnIzDZlem9mr/t686EEWAysjGlnB3Nnf8ZxI3Csmb3lbQH/6OvKSFVNElIGCW3btmX06NG0b9+ehg0bMmTIEIYMGZJ3PYFAILA9UFCTBEkXAifjXHM+AV4BuuEMBu6TNBE4BtiEOwj6AVzg/K+/TsAt3BloZu/F1N8TZx7QGPgUKDGzj7zJwAu4Fa7NccepvQAsBRoCH+LMEmbj9lh2x/0hMc7MZkkqwc0x7gw0MrNDiEHSubgzOHcCZprZRd5A4VHgn8CPfFvH+vpK/XNqIdBbOFehIb7MCWaWMuLvCEw3s56SlgAnm9kLki4AmpjZ/8boqbZJQsogYc2aNVx00UWMHTuWxo0bM27cOA4++GAGDx6cd12ZSNJG6ChJ1JVETZBMXUnUBMnUlURNkCxddW6SAPTErTTdBWiKC1yjcQFkKNACWMKWAN7c/yxli5lAE2B1hvp3BJ4FWvrnYcAU22IyMMnfHwH8w9+XANdF6rgMOCnVPm5VbCOfbwXQIsv3DQH+htsz2gAXiPvjDBQ2AcU+34xIG2VUND9YDpwXeZ4XKXcZcJa/Pwj4zGt6E2ia6/dfXZOEGTNm2IgRI8qfp02bZmeeeWa16konSRuhoyRRVxI1mSVTVxI1mSVTVxI1mSVLFwkwSTgI1xtbb2ZfAg+lvf8S+Aq4xVvZrY+pI5OZAUBnXC92rt+K8kegXeT9A/7nK7iAFscQYIwvX4brabb37+aa2ecZyqXKDsH5074K7AN09O+WmVlqe0y29gHuidzfApzqzeeHseXw7LOBI8ysHTAV19suCO3bt+f5559n/fr1mBlPPPEEXbp0KVRzgUAgUC8p9JxnxjFhM9skqTfOkP1nuG0dh6Tl+VLSOkl7mtn7aVUIeMPM+mVo4mv/czOZv1O4odIlFRKlPuR2FBIwwcz+mla2Q6TtVPsNs9QTbed+nAH9k8Ar5vaTtgR+aGapRUj3AI/l0FZt+vTpw9ChQ+nRowdFRUXsv//+/OpXvypUc4FAIFAvKWTP82ngeEkNJTUBjo6+lNQYaGZmc4BRbFl0k+6uMwG43pu3I6mpn9tbArSU1M+n7yipaw5N6XX/HTjLn4CCpP2r8H1/B0b470BSW0mtqth+BczsK1/vjbgeJsBqoJmkTv55MG6utGBcfPHFvP322yxevJjbb7+dnXbaqZDNBQKBQL2jYMHTzF7F9ZIW4HpU6ZY1TYDZkhbh3HfO9unTgXMlvSZpL1wgmQe85B19nsIZtm/EzZ1eLmmhb+dHOWTNA/b1Wz6GAZfg5k4X+bovqcL3PY4bVn1O0uvAfeS27CvFOQct8M5GcdyJ67E/7tvZBJyBcz5aiLMNjHM0qjGuuuoqunbtSrdu3Rg+fDhfffVVIZsLBAKBekdBh23N7FLg0ixZeseUmQ/sm5Z8hb/S8y7ALdJJTx8Quf8UP+fo5zAPSMv+65jypbhAlxUzm4w7EzSdbpE8V0bu052DOsSUPRC38Kl824qZzcTZ/RWclEnCm2++ScOGDTnxxBOZPn06JSUltdF8IBAI1Au2eYchSZvTDAzG1ECdzf1+y6qUKZU01N/fkm4E4dNn4rb2/CdqpiDpTklLvEnEFEk7bu03ZCOYJAQCgUB2tnlvW2CDmeVrYlAJSd1xZ3xGMdxw7w3VqdPMYo3dzex432YZ8DxbzBTuBE7y93fhjOFvrE7buQgmCYFAIJCb7SF4xuKPI5uM29f5NW7V73dxgbKRzzbSzJ6VNAq3CvYj3MKmRcCxfovLXIs5VcUvQroWt4J4GW51bupdGW7P62vArTjXI8MZJnzgn+9MnariF1Wlyr5IxS05sVTXYWj16tXMmjWLZcuW0bx5c376059yxx13cNJJJ+WoIRAIBLYftofgmX4k2QTc/OE9wDAze8mv5N0ArAIGm9lX3uHnblwgA2Ujck0AABoYSURBVDc/283MlvntKN1y9GiPx+1F7Q7sjjM3mJKWpxhoa2bdwA0Hm9kXkkYCo83s5WhmP1z7S+D3cQ2mOQwxtntGV8FKlJWVlf/ceeedeeONNwDo0qUL9957L+3a5YzXOVm7dm15O0kiibqSqAmSqSuJmiCZupKoCZKrKyv5OCnU5wtYG5PWHZgfk94M1/N8Hbd6d71PHwDMi+TrACzO0e7VwIjI8wNscU4qwwXlXYH3cD3UH+MOxi5/H1PnzcDV+Xx3dR2Gnn/+edt3331t3bp19u2339rJJ59s11xzTbXqSidJLiJRkqgriZrMkqkriZrMkqkriZrMkqWLBDgMJZlMzkVnA/8BfogLbt+JvMtlmhBHVuNgM1vt2yoDfotzGIpF0kVAS+CcaujIm6hJQvfu3fn222+DSUIgEAiksb0Gz7eBNn7eE0lNJBXhep4fmdm3uOHR2IO0yWF24Hka+JmkHSS1xpnUV0DSbrje5v3An9hyMHaF+iWdDhwGDPfaCkowSQgEAoHsbI9zno+Z2RhvknCtNyvYAByKWz17v6Sf4gwVYnub5mzz5ntjhUctZsEQbl71ENwQ8Ds4c4d02gJTJaX+iLnA/yzFmSmkTl+5CfgXzpAB4AEzG5/f5wcCgUCgptnmg6eZxfYezewloG9a8rvAfpHnC3zeMtzQarT8z3O0azi/3rh3AyKPPWLep5sp1Mq/05IlSxg2bFj58/vvv8/48eMZNWpUbTQfCAQC9YZtPngG8qdz584sWOA66Zs3b6Zt27Ycf/zxdawqEAgEksf2OudZY0jqnuZgtEDSCzH5SqKuQVWoX5IulfSOpLck/a5mlGfniSeeYK+99mKPPfaojeYCgUCgXhF6nluJmb3OlhNhslECLGaLa1A5knawiJdtTLnvA/uY2bd5nNwC5G+SkDJHSGf69OkMHz48n6YCgUBgu0Nuai4A5a5Dt+IMEXYAXsQZKSyOyXsucCKwE+7Q74u8ecKjwD9xJ7x8CBwLHIlbBPQhbnFSP9yxYlNwB2o/ijtXtIevuyMw3cx6ekehn5vZ0jz0R00Seo69+uac39y9bbNKad988w1Dhw5l6tSptGjRImcd+bJ27VoaN25cY/XVFEnUlURNkExdSdQEydSVRE2QLF0DBw58xcx65cyYz2bQ7ekC/gxcCVwPXJAhzxDgb7j9og2A2bjTXToAm4Bin28GcJLFGB8Ay4HzIs/zIuUuA87y958BFwIv44Jsx3y+o7omCWZmDz74oA0ePLja5TORpI3QUZKoK4mazJKpK4mazJKpK4mazJKli2CSUG3G4w6c7kXMMWieIf56DXgV2Afo6N8tM3dUGsArxB87luKeyP0twKmSdgCG4QzgwfVsvzL3l9DNVLb4q3HuvvvuMGQbCAQCWQjBszItgMY4k4KdM+QRMMHMiv21t5nd6t99Hcm3mezzytF9pPcDhwNHAa+Y2Wc+fcX/b+/Mo+wq6jz++U4AJSHLBKIsYiCKSEawIQZxBIwLW1QIIU6DeCAsZ3AQh+DBEQ6jMHEJi0swogTIYpywTSSQo+OQyGJckMWQkCi0CQ0KYwYExYgBs/ibP6pe+ub1u2/p7ndfdef3Oeeed2/duq++t97r9+uqW/UtuqatLGb7qTR9zsaNG1m2bBmTJ09uZjGO4zj9Gg+e3bmB4PazELgqJ8/dwNmSdgOQtE8dA3mquhKZ2avxfb8FzMucupNgtgDwHoLhQtMYPHgwL774IsOHd38W6jiO4wQ8eGaQdAawxcxuBq4Exkt6X3k+M1tK6FZ9QNJqYBG17frmE1yDVkZXo0osJPjhLs2kXQmcEsuZQVjLsyl0dHTQ1ta2bRs2bBgzZ85sVnGO4zj9Fp+qksHMFgAL4v5W4J1V8l5LWA+0nLdl8nw5s1/uGrRfhWuPBOZaZtqKmb1EGK3bdNwkwXEcpz48eBaEpKnAUjPrNs8znl8MvImuLtpS+kLC4KXNhKkz55nZ5uaqdZMEx3Gcani3bRXqdQ+qk6lARYehaJJwspkdYmYvlJ1eSBjNezCwK03sts3iJgmO4zj5eMszg6TPAy/ELlmAUwndqF+vkLdRk4R3AAszK6VsZ5IgqaJJgpn9d6bMh4A31HMvvXEY2rRpE0uWLGHGjBn1FOU4jrPD4Q5DGWLwu8PMDovLhK0FDs9MGynlOxaYApxHmLayhDAn9LfAOoIZwkpJtwNLzOw/Jd0PXGxmj8T3eBr4ppldHY/vAy6K132JsK7orEyZOwMPAhea2Y9z9G9zGBo1atS422+/vUf18JOf/IS77rqLa665pkfX55GSi0iWFHWlqAnS1JWiJkhTV4qaIC1d7jDUc4ehZcChwPHAopw8XyY4BK2M2zrgHMIgoLWZfJ8B/t3yHYZGZ45PJwxAGgQ8CexeVuaNwMx676M3DkPt7e02d+7cHl+fR0ouIllS1JWiJrM0daWoySxNXSlqMktLF3U6DHm3bXduIjyf3JN8N5+SScLs7RJDy7XcJCFvWgp0N0m4HLiX7U0SkHQ5MIrQ0m0qJZOE2bNn187sOI6zg+IDhrqzmNDqHE8wLahEYSYJks4FjgNOM7O/1XsTPcVNEhzHcWrjLc8yzGxTfP74kuUsE2ZmSyUdRDBJAHgZ+BihpZnHfIJJQmnAUCUWApPZ3iTheuA3mbLuMLPp9d+R4ziO09d48CwjDhQ6AvhItXxWnElCYZ9RR0cH7e3t2447OzuZPn0606ZNK0qC4zhOv8CDZwZJYwnLiy02s7UFl13RJKFI3GHIcRynPjx4ZjCzXwFjSseSDga+U5btr2aWa9tXjWouQ2aWG6UkzSHMExXBGH6qmb3cEw314g5DjuM4+XjwrIKZrQba+vAtpwJrgG7BM7oM5T0zvcjMNsR8XwUuIBjG59IbkwRwhyHHcZxquElCGZLGA3OAwwlzLh8C2s1sTYW8jboMzY/HFV2GgIouQ5nyBHwTeNrMui2XljVJ2GOPUeM+N/PGmvd78D7dR9Vu3ryZKVOmMG/ePEaOHFnzPeolpYnQWVLUlaImSFNXipogTV0paoK0dLlJQu+MEr5AMEK4Drg0J8+xhLU/RZjy8z3gaMJAoC1AW8x3O/AxyzdK+LfM8X2Z674EfDJzbh7wXMwzuNY99MYk4c4777Rjjjmmx9fnkdJE6Cwp6kpRk1maulLUZJamrhQ1maWlizpNEnyeZ2WmA8cQnjNenZPn2Lg9CqwgmLcfEM89ZWYr4/4vqDyytsRtmf2bgLMkDQLaCWuGAmBmZxGM5R+P55rGLbfc4l22juM4VfDgWZmRwG4EU4PX5uQpuQy1xe3NZjYnnit3Gar2bLncZegE4EOUuQzBtjVGbwNOqftOGqTkMDR58uRmFeE4jtPv8eBZmRuAzxJMC7o9W4wU4jKkwJtL+8CHgSfqv5XGcIchx3Gc2njwLEPSGcAWM7uZMKJ1vKRucy/NbCmhW/UBSauBRVQJjJH5BJehlZLyPG8XAkaXy5CAb8cyVgN7EbqV+5yOjg7a2tq2bcOGDWPmzJnNKMpxHKdf41NVyjCzBcCCuL8VyJ3TaQW4DFnws313/XfQc9wkwXEcpz4KC56SriB4wA4DlpvZD3PyTQJ+bcGwoJR2MXAuYRTrVuArMcg1qqEN2NsyC0wXSTWThHi+osuQpB/T1ap9HfCQmU1qolQ3SXAcx6lC4S1PM/tcjSyTCNM+fgUg6eOEka+Hm9kGScNjnp7QRhhBW3fwjAF3fllyT12GplLdJKFiM8/Mjsrk+y5wV62C3CTBcRyneTTVJEHSZcAZwDPA7wnTNt4GfM/MFkm6EjiR0KJcCtxBCJx/itsphHmN7zWzJyu8/zjgq4SRsS8QbOvWS7ofeBB4LzCCsFD1g4RFq3clGBXMiGXNAg4m/CNxhZndFVuIHySMtB1iZhX9ZltgkjAU+C1hEe0NFfS4SUIPSFFXipogTV0paoI0daWoCdLS1XKTBGAcYYDLYEJX7TrgYkIAmUKYDtJBVwAfEV/nA1Pi/lDgjznvvzPwM2BUPG4nPCuEYEbwlbg/Efhh3J8KfCPzHl+iy8BgBME3dkjM9ywwssr9FWqSENPOABbVU/9uklA/KepKUZNZmrpS1GSWpq4UNZmlpYs6TRKa2W17FKE1thFA0pKy8xuAV4GbJH2fEHzKEWHkaSUOJLRil8V1LgcB6zPn74iv1UwKjgVOjM9UIbQ03xj3l5nZH3KuK11bMkmA0Po9gNAyfMp6Z5LwKcI/A4eX5T0t5mkqbpLgOI5TnWY/88ztEzazLZIOB94PnEowO39fWZ4Nkv4iaYyZdZa9hYBfmlnewtIlo4JqJgUidJV2bJcovZPtzQvyrp1hZrPLrt2P7iYJedNSoLtJwuXAvZSZJEjanRBMmzr8tWSSMHv27NqZHcdxdlCaOc9zOXCypF3js7oPZ09Gc4HhFka+TqNr9ZJyI4EZwHWShsXrhsVnex3AKEnviuk7S/qHGprK3/tu4JPRfABJhzZwf4WYJGT4COFZ8asNaGwYN0lwHMepTdOCp5mtIHRJriS0qH5clmUo8D1JjwE/Ai6K6bcCn5b0qKQ3EQLJfcDDktbEvBvNbBPh2elVklbFcv6xhqz7gLHRpKAd+Dzh2elj8b0/38D9FWWSUOJU4JZ69TmO4zjNo6ndtmb2ReCLVbKUP9PDzH4KjC1LvpoKBu3xueLRFdInZPZfID5zjM8wx5dlP6/C9fPpPj2lG1aASULm2gm19PSWjo4O2tu7POc7OzuZPn0606ZNa3bRjuM4/Qp3GEqIPJOEonCHIcdxnPrw4FkDSQcD3ylLbtgkoZa7EIBVMEmQtJBg7LCZsDD3eWa2uZGye4I7DDmO4+TjwbMGZraarsFMvWEq1d2Ftna7IrAQ+Fjcv5lgU/itWoW5w5DjOE7zaKrDUH9D0nhgDuFZ7CBCS6/dzNZUyFuou1BMvwjYw8wuy9HvDkM9IEVdKWqCNHWlqAnS1JWiJkhLV8sdhvrrBnwB+DJwHXBpTp5WuAvtDKwAjqrnPtxhqH5S1JWiJrM0daWoySxNXSlqMktLFwk4DPVXpgMPE9yP/jUnTyvchb5JWI2mfMpPn+MOQ47jONXxxbC7M5IQDIcS7PoqUXIXaovbm81sTjxX7i5U7R+UcnehE4AP0d1d6HJgFPCphu6kB5QchiZPntzsohzHcfotHjy7cwPwWcJAnaty8hTmLiTpXOA44DQLC2M3FXcYchzHqY0HzwySzgC2mNnNwJXAeEnd5lxase5C1wOvj2WtlFRrPdQe8dJLLzFlyhTe+ta3ctBBB/HAAw80oxjHcZwBgT/zzGBmC4AFcX8rkDuX0wpyFzKzQj6jCy+8kOOPP55FixaxadMmNm7cWESxjuM4/ZIB3/KUtDW22ErbJX3wniMknd/gNfMlTYn7N0kaW3Z+MWG9zmslTZW0d+bc/pIelLRW0m2SduntPWTZsGEDy5cv55xzzgFgl112YcSIEX1ZhOM4zoBiR2h5vmJmPTI5yHMXIoyGPZ8wArZhzOzcCmnb3IWiG1HWUOEq4Gtmdquk64FzqGGUUI9JQskgobOzk1GjRnHWWWexatUqxo0bx7XXXsuQIUMauCvHcZwdhwFvkiDpZTPrNvs2GiJcCwwhBMT3A7sTgmUpalxgZj+TNIGwzuZ6gtvQYwTzgw7CotmfrvD+AmYRfGqfIozQnWtmiyTdD1xMmOoyh2C/ZwTThGfobqjwDLCnhTVQ3wVcYWbHVSizIZOEkkFCR0cH559/PrNmzWLs2LHMmjWLIUOGcPbZZ1e9vlFSmgidJUVdKWqCNHWlqAnS1JWiJkhLl5skdJkLbCUsV1ba2oFdgE5gfMwzjNAKHwy8NqYdQJwsC0wgTCvZPx7vB6ypUe5kYBnBqWhv4CVgimUME4BxhOBbumZE9nzc3wNYl8mzb62yrUGThPXr19vo0aO3HS9fvtwmTpxY9/X1ktJE6Cwp6kpRk1maulLUZJamrhQ1maWlCzdJ2Ea3btvYHbvezB4GMLMNMX0I8A1JbYSg+5bMZQ+Z2VMNlHs0cIuFwT+/k3RvhTydwBhJs4Dv030NTwgt1nL6tLtgzz33ZN9996Wjo4MDDzyQe+65h7Fjy1eFcxzHcUrsCMGzEqJyALoIeA54O2Ew1auZc3+pkL8WVYOcmf1R0tsJ8zg/QfDKLe8rfQEYIWknM9sCvIEK5vK9ZdasWZx++uls2rSJMWPGMG/evNoXOY7j7KDsqMHzCWBvSePN7GFJQwnPF4cDz5rZ3ySdSehyrURVw4PIcuA8SQuA1wHvJcwN3YakPYBNZvZdSU/StQD3tvc3M5N0HzAFuBU4E7irobutg7a2Nh555JG+flvHcZwByY4QPHeVtDJz/D9mdomkdmBWNCx4BfgAYfTsdyV9hGDUXrG1aWYvSvqppDXAD6zCgCFgMWGw0Grg18CPKuTZB5gnqTRl6NL4Op9gqFAaMPQZ4FZJX6BrkJHjOI7TIgZ88DSziq3H+LzziLLktcAhmeNLY977CYN4std/tEa5BlyQc25C5vCwCufLDRU66W4U7ziO47SIAW+S4DiO4zh9zYBveTabPCMFM8u19nMcx3H6Nx48e4mZrSYYJziO4zg7CAPeYWhHRdKfCQ5IKbEHYepNaqSoK0VNkKauFDVBmrpS1ARp6RptZqNqZfKW58Clw+qxmCoQSY+kpgnS1JWiJkhTV4qaIE1dKWqCdHVVwwcMOY7jOE6DePB0HMdxnAbx4DlwuaHVAiqQoiZIU1eKmiBNXSlqgjR1pagJ0tWViw8YchzHcZwG8Zan4ziO4zSIB0/HcRzHaRAPngMMScdL6pC0TtIlLdSxr6T7JD0u6ZeSLozpV0j6X0kr4zaxYF1PS1ody34kpo2UtEzS2vj69wVrOjBTHyslbZA0rei6kjRX0vNxwYNSWsW6UeDr8Xv2mKRuHs1N1nWNpCdi2YsljYjp+0l6JVNn1xeoKffzknRprKsOScc1Q1MVXbdlND1dWiijwLrK+y1o+XerV9SzYrZv/WMjLKH2JDAG2AVYBYxtkZa9gMPi/lDCyjJjgSuAi1tYR08De5SlXQ1cEvcvAa5q8Wf4f8DoouuKsID7YcCaWnUDTAR+QFgb9wjgwYJ1HQvsFPevyujaL5uvYE0VP6/4vV8FvAbYP/6NDipKV9n5rwCfK7iu8n4LWv7d6s3mLc+BxeHAOjPrNLNNhPU/T2qFEDNbb2Yr4v6fgccJS7ClyEnAt+P+t4FJLdTyfuBJM/tN0QWb2XLgD2XJeXVzErDAAj8nLNi+V1G6zGyphcXhAX5OWCS+MHLqKo+TgFvN7K9m9hSwjiatklRNlyQB/wTc0oyyq2jK+y1o+XerN3jwHFjsAzyTOX6WBAKWpP2AQ4EHY9IFsTtmbtFdpIABSyX9QtI/x7TXm9l6CH/ohMXLW8WpbP/j1sq6gvy6Sem7djahpVJif0mPSvqRpKMK1lLp80qlro4CnjOztZm0Quuq7LegP3y3cvHgObBQhbSWzkWStBthbdJpZrYB+BbwJoKZ/npCN1KRvNvMDgNOAD4h6eiCy89F0i7AicB/xaRW11U1kviuSboM2AIsjEnrgTea2aHAp4CbJQ0rSE7e55VEXQGnsf0/ZoXWVYXfgtysFdKSm1PpwXNg8Sywb+b4DcDvWqQFSTsT/lgWmtkdAGb2nJltNbO/ATdS8CLfZva7+Po8sDiW/1ypWyi+Pl+kpgwnACvM7LmosaV1Fcmrm5Z/1ySdCXwION3iw7LYNfpi3P8F4fniW4rQU+XzSqGudgImA7eV0oqsq0q/BST83aoHD54Di4eBAyTtH1sxpwJLWiEkPl+ZAzxuZl/NpGefXZwMrCm/tomahkgaWtonDDpZQ6ijM2O2M4G7itJUxnYtg1bWVYa8ulkCnBFHRh4B/KnUBVcEko4HPgOcaGYbM+mjJA2K+2OAA4DOgjTlfV5LgFMlvUbS/lHTQ0VoyvAB4Akze7aUUFRd5f0WkOh3q25aPWLJt77dCCPVfk34L/KyFuo4ktDV8hiwMm4TCQuHr47pS4C9CtQ0hjDqcRXwy1L9ALsD9wBr4+vIFtTXYOBFYHgmrdC6IgTu9cBmwn//5+TVDaFr7br4PVsNvKNgXesIz8VK363rY95T4me7ClgBfLhATbmfF3BZrKsO4IQi6yqmzwc+Xpa3qLrK+y1o+XerN5vb8zmO4zhOg3i3reM4juM0iAdPx3Ecx2kQD56O4ziO0yAePB3HcRynQTx4Oo7jOE6D7NRqAY7j9B8kbSVMHygxycyebpEcx2kZPlXFcZy6kfSyme1WYHk7WZcBvOMkg3fbOo7TZ0jaS9LyuD7kmpLZuMI6syskrZJ0T0wbKenOaKT+c0mHxPQrJN0gaSmwQNIghfU7H455z2vhLToO4N22juM0xq6lxZSBp8zs5LLzHwXuNrMvRuu3wZJGEbxejzazpySNjHn/A3jUzCZJeh+wgGCqDjAOONLMXomr3/zJzMZLeg3wU0lLLSzv5TgtwYOn4ziN8IqZtVU5/zAwNxqB32lmKyVNAJaXgp2ZldabPJJgEYeZ3Stpd0nD47klZvZK3D8WOETSlHg8nODD6sHTaRkePB3H6TPMbHlc5u2DwHckXQO8ROUlpaotPfWXsnyfNLO7+1Ss4/QCf+bpOE6fIWk08LyZ3UhYSeMw4AHgPXFFETLdtsuB02PaBOAFq7zO493Av8TWLJLeElfFcZyW4S1Px3H6kgnApyVtBl4GzjCz38fnlndI+jvCuo3HAFcA8yQ9Bmyka3mqcm4C9gNWxOWtfg9MauZNOE4tfKqK4ziO4zSId9s6juM4ToN48HQcx3GcBvHg6TiO4zgN4sHTcRzHcRrEg6fjOI7jNIgHT8dxHMdpEA+ejuM4jtMg/w+C7o0ul4rdvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot feature importance using built-in function\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "\n",
    "# plot feature importance\n",
    "plot_importance(clf,max_num_features=22)\n",
    "pyplot.savefig('feature_imp.png', bbox_inches='tight')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# #calculs des angles\n",
    "\n",
    "#X[14] X[15] x et y entry\n",
    "#X[16] X[17] x et y exit\n",
    "#(3750901.5068+3770901.5068)/2 x centre\n",
    "# = 3760901.5068\n",
    "#(-19268905.6133+-19208905.6133)/2\n",
    "# = -19238905.6133\n",
    "\n",
    "# u = np.array([train.x_exit,train.y_exit])-np.array([train.x_entry,train.y_entry])\n",
    "# v = np.array([x_centre-train.x_entry,y_centre-train.y_entry])\n",
    "\n",
    "# angle_train = []\n",
    "# for i in range(u.shape[1]):\n",
    "#     scalar = (np.dot([u[0][i],u[1][i]],[v[0][i],v[1][i]]))\n",
    "#     u_norm = (np.linalg.norm([u[0][i],u[1][i]]))\n",
    "#     v_norm = (np.linalg.norm([v[0][i],v[1][i]]))\n",
    "#     angle_train.append(degrees(acos(scalar/(u_norm*v_norm))))\n",
    "    \n",
    "# u = np.array([test.x_exit,test.y_exit])-np.array([test.x_entry,test.y_entry])\n",
    "# v = np.array([3760901.5068-test.x_entry,-19238905.6133-test.y_entry])\n",
    "\n",
    "# angle_test = []\n",
    "# for i in range(u.shape[1]):\n",
    "#     scalar = (np.dot([u[0][i],u[1][i]],[v[0][i],v[1][i]]))\n",
    "#     u_norm = (np.linalg.norm([u[0][i],u[1][i]]))\n",
    "#     v_norm = (np.linalg.norm([v[0][i],v[1][i]]))\n",
    "#     angle_test.append(degrees(acos(scalar/(u_norm*v_norm))))\n",
    "\n",
    "# #application\n",
    "\n",
    "# train['angle']=angle_train\n",
    "# test['angle']=angle_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-01 23:46:30.896014\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  20 | elapsed:  6.8min remaining: 27.4min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed: 13.6min remaining: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  20 | elapsed: 16.4min remaining:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed: 16.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-02 00:04:51.994189\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# print(datetime.datetime.now())\n",
    "# X = X\n",
    "# y = Y.astype(int)\n",
    "# param_grid = {\n",
    "#     'n_jobs':[-1],\n",
    "#     'n_estimators': [100,150,200,300],\n",
    "#     'learning_rate': [0.01,0.05,0.1],\n",
    "#     'max_depth': [5,12,14,17,19],\n",
    "#     'min_child_weight': [0.4],\n",
    "#     'n_jobs':[-1],\n",
    "#     'colsample_bytree':[0.3,0.5,0.8],\n",
    "#     'subsample' :[0.8,1]\n",
    "# }\n",
    "# XGBClassifier()\n",
    "\n",
    "# kf = StratifiedKFold(n_splits=4,random_state=1,shuffle=True)\n",
    "# random_search = RandomizedSearchCV(XGBClassifier(),param_grid,n_iter=5, cv=kf.split(X, y),verbose=3, scoring= 'f1',iid=True,n_jobs=-1)\n",
    "# random_search.fit(X,y)\n",
    "\n",
    "# print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_n_jobs</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>805.915529</td>\n",
       "      <td>30.117864</td>\n",
       "      <td>2.281324</td>\n",
       "      <td>0.312950</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885611</td>\n",
       "      <td>0.887532</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985967</td>\n",
       "      <td>0.986059</td>\n",
       "      <td>0.984791</td>\n",
       "      <td>0.986131</td>\n",
       "      <td>0.985737</td>\n",
       "      <td>0.000549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>387.715264</td>\n",
       "      <td>15.529830</td>\n",
       "      <td>0.968381</td>\n",
       "      <td>0.125880</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883610</td>\n",
       "      <td>0.885576</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>2</td>\n",
       "      <td>0.896642</td>\n",
       "      <td>0.897159</td>\n",
       "      <td>0.896381</td>\n",
       "      <td>0.898186</td>\n",
       "      <td>0.897092</td>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>484.345139</td>\n",
       "      <td>4.387443</td>\n",
       "      <td>1.610464</td>\n",
       "      <td>0.189231</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881857</td>\n",
       "      <td>0.884363</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.999267</td>\n",
       "      <td>0.999011</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>0.999143</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>416.211441</td>\n",
       "      <td>15.038476</td>\n",
       "      <td>3.769427</td>\n",
       "      <td>0.333052</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881626</td>\n",
       "      <td>0.883667</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.998791</td>\n",
       "      <td>0.998864</td>\n",
       "      <td>0.999084</td>\n",
       "      <td>0.998983</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536.482058</td>\n",
       "      <td>2.363955</td>\n",
       "      <td>3.782681</td>\n",
       "      <td>0.427133</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876413</td>\n",
       "      <td>0.877536</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>5</td>\n",
       "      <td>0.945794</td>\n",
       "      <td>0.946021</td>\n",
       "      <td>0.945636</td>\n",
       "      <td>0.946636</td>\n",
       "      <td>0.946022</td>\n",
       "      <td>0.000380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     805.915529     30.117864         2.281324        0.312950   \n",
       "2     387.715264     15.529830         0.968381        0.125880   \n",
       "3     484.345139      4.387443         1.610464        0.189231   \n",
       "1     416.211441     15.038476         3.769427        0.333052   \n",
       "4     536.482058      2.363955         3.782681        0.427133   \n",
       "\n",
       "  param_subsample param_n_jobs param_n_estimators param_min_child_weight  \\\n",
       "0             0.8           -1                200                    0.4   \n",
       "2               1           -1                200                    0.4   \n",
       "3             0.8           -1                150                    0.4   \n",
       "1               1           -1                200                    0.4   \n",
       "4               1           -1                300                    0.4   \n",
       "\n",
       "  param_max_depth param_learning_rate  ... split3_test_score mean_test_score  \\\n",
       "0              12                0.05  ...          0.885611        0.887532   \n",
       "2               5                0.05  ...          0.883610        0.885576   \n",
       "3              14                 0.1  ...          0.881857        0.884363   \n",
       "1              12                 0.1  ...          0.881626        0.883667   \n",
       "4              12                0.01  ...          0.876413        0.877536   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.001330                1            0.985967            0.986059   \n",
       "2        0.001217                2            0.896642            0.897159   \n",
       "3        0.001709                3            0.999194            0.999267   \n",
       "1        0.001429                4            0.999194            0.998791   \n",
       "4        0.001348                5            0.945794            0.946021   \n",
       "\n",
       "   split2_train_score  split3_train_score  mean_train_score  std_train_score  \n",
       "0            0.984791            0.986131          0.985737         0.000549  \n",
       "2            0.896381            0.898186          0.897092         0.000691  \n",
       "3            0.999011            0.999102          0.999143         0.000096  \n",
       "1            0.998864            0.999084          0.998983         0.000163  \n",
       "4            0.945636            0.946636          0.946022         0.000380  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(random_search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-02 00:17:07.161631\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed: 145.5min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 535.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8877009016037539\n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 0.4, 'n_estimators': 230, 'n_jobs': -1, 'subsample': 0.8}\n",
      "2019-05-02 09:14:34.590405\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "X = X\n",
    "y = Y.astype(int)\n",
    "param_grid = {\n",
    "    'n_jobs':[-1],\n",
    "    'n_estimators': [170,200,230],\n",
    "    'learning_rate': [0.02,0.05],\n",
    "    'max_depth': [10,12],\n",
    "    'min_child_weight': [0.4],\n",
    "    'n_jobs':[-1],\n",
    "    'colsample_bytree':[0.8],\n",
    "    'subsample' :[0.8,1]\n",
    "}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10,random_state=1,shuffle=True)\n",
    "model = GridSearchCV(XGBClassifier(),param_grid, cv=kf.split(X, y),verbose=3, scoring= 'f1',iid=True,n_jobs=-1)\n",
    "model.fit(X,y)\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)\n",
    "\n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pickle.load(open('V2_XGB_best.pickle', 'rb'))\n",
    "pickle.dump(model.best_estimator_,open('XGB_tuned_01','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "#model = CatBoostClassifier()\n",
    "model = XGBClassifier(random_state=1,n_jobs=-1)\n",
    "#model = LGBMClassifier(random_state=1,n_jobs=-1)\n",
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X =pd.read_csv('X.csv')\n",
    "# X_test = pd.read_csv('X_test.csv')\n",
    "# Y = pd.read_csv('Y.csv')\n",
    "\n",
    "# model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "#pred = model.predict_proba(X_test)\n",
    "prediction = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = pd.DataFrame(pred)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_id = tr['trajectory_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_id=trajectory_id.values\n",
    "prediction['id']=trajectory_id\n",
    "prediction['target']=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pTreshold = np.where(prediction['target'] > 0.4565999999999999, 1,0)\n",
    "# prediction['target'] = pTreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25230\n",
       "1     8285\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33515.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.247203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.431392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             target\n",
       "count  33515.000000\n",
       "mean       0.247203\n",
       "std        0.431392\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.target = prediction.target.astype(int)\n",
    "prediction.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#findOptimalTreshold(model,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv(\"XGB_douille.csv\",index=False)\n",
    "#0.46109999999999995 treshold\n",
    "#0.8893500488666778"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 1ère Version\n",
    "# print(model.best_params_)\n",
    "{'eta': 0.1, 'max_depth': 8, 'min_child_weight': 0.5, 'n_jobs': -1, 'num_boost_round': 100}\n",
    "\n",
    "# 2ème Version\n",
    "# print(model.best_params_)\n",
    "{'eta': 0.2, 'max_depth': 8, 'min_child_weight': 0.5, 'n_jobs': -1, 'num_boost_round': 70}\n",
    "\n",
    "# 3ème\n",
    "{'eta': 0.2, 'max_depth': 8, 'min_child_weight': 0.4, 'n_jobs': -1, 'num_boost_round': 70}\n",
    "\n",
    "# 4ème version randomSearch\n",
    "{'subsample': 1,\n",
    " 'num_boost_round': 90,\n",
    " 'n_jobs': -1,\n",
    " 'min_child_weight': 0.5,\n",
    " 'max_depth': 11,\n",
    " 'gamma': 5,\n",
    " 'eta': 0.15,\n",
    " 'colsample_bytree': 0.8}\n",
    " \n",
    " #Gridsearch\n",
    " {'colsample_bytree': 0.5,\n",
    " 'eta': 0.1,\n",
    " 'gamma': 5,\n",
    " 'max_depth': 15,\n",
    " 'min_child_weight': 0.5,\n",
    " 'n_jobs': -1,\n",
    " 'num_boost_round': 70,\n",
    " 'subsample': 1}\n",
    " \n",
    " #GridSearch\n",
    " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.5, eta=0.001, gamma=5, learning_rate=0.1,\n",
    "       max_delta_step=0, max_depth=14, min_child_weight=0.4, missing=None,\n",
    "       n_estimators=170, n_jobs=-1, nthread=None,\n",
    "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "       subsample=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseaux neuronnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import theano # utilise à la fois le Cpu et le Gpu de l'ordinateur\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X1_train=scaler.fit_transform(X_train)\n",
    "X1_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=108,activation=\"relu\",kernel_initializer=\"uniform\",input_dim=217)) #1ere couche\n",
    "classifier.add(Dense(units=108,activation=\"relu\",kernel_initializer=\"uniform\")) #couche cachée\n",
    "classifier.add(Dense(units=1,activation=\"sigmoid\",kernel_initializer=\"uniform\")) #to get a proba\n",
    "classifier.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100547/100547 [==============================] - 18s 178us/step - loss: 0.2870 - f1: 0.6663\n",
      "Epoch 2/100\n",
      "100547/100547 [==============================] - 18s 182us/step - loss: 0.2151 - f1: 0.7540\n",
      "Epoch 3/100\n",
      "100547/100547 [==============================] - 18s 180us/step - loss: 0.2037 - f1: 0.7633\n",
      "Epoch 4/100\n",
      "100547/100547 [==============================] - 19s 185us/step - loss: 0.1963 - f1: 0.7669\n",
      "Epoch 5/100\n",
      "100547/100547 [==============================] - 18s 183us/step - loss: 0.1917 - f1: 0.7753\n",
      "Epoch 6/100\n",
      "100547/100547 [==============================] - 17s 169us/step - loss: 0.1888 - f1: 0.7777\n",
      "Epoch 7/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1871 - f1: 0.7829\n",
      "Epoch 8/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1835 - f1: 0.7835\n",
      "Epoch 9/100\n",
      "100547/100547 [==============================] - 17s 170us/step - loss: 0.1826 - f1: 0.7886\n",
      "Epoch 10/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1799 - f1: 0.7885\n",
      "Epoch 11/100\n",
      "100547/100547 [==============================] - 17s 170us/step - loss: 0.1768 - f1: 0.7900\n",
      "Epoch 12/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1751 - f1: 0.7900\n",
      "Epoch 13/100\n",
      "100547/100547 [==============================] - 17s 170us/step - loss: 0.1732 - f1: 0.7933\n",
      "Epoch 14/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1721 - f1: 0.7946\n",
      "Epoch 15/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1709 - f1: 0.7983\n",
      "Epoch 16/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1703 - f1: 0.8018\n",
      "Epoch 17/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1678 - f1: 0.7967\n",
      "Epoch 18/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1652 - f1: 0.8036\n",
      "Epoch 19/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1647 - f1: 0.8032\n",
      "Epoch 20/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1630 - f1: 0.8098\n",
      "Epoch 21/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1615 - f1: 0.8072\n",
      "Epoch 22/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1601 - f1: 0.8048\n",
      "Epoch 23/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1591 - f1: 0.8111\n",
      "Epoch 24/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1580 - f1: 0.8081\n",
      "Epoch 25/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1564 - f1: 0.8156\n",
      "Epoch 26/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1554 - f1: 0.8109\n",
      "Epoch 27/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1544 - f1: 0.8141\n",
      "Epoch 28/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1535 - f1: 0.8132\n",
      "Epoch 29/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1526 - f1: 0.8131\n",
      "Epoch 30/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1513 - f1: 0.8151\n",
      "Epoch 31/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1506 - f1: 0.8181\n",
      "Epoch 32/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1498 - f1: 0.8183\n",
      "Epoch 33/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1483 - f1: 0.8171\n",
      "Epoch 34/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1474 - f1: 0.8190\n",
      "Epoch 35/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1472 - f1: 0.8169\n",
      "Epoch 36/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1463 - f1: 0.8182\n",
      "Epoch 37/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1447 - f1: 0.8237\n",
      "Epoch 38/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1442 - f1: 0.8236\n",
      "Epoch 39/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1429 - f1: 0.8256\n",
      "Epoch 40/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1443 - f1: 0.8252\n",
      "Epoch 41/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1421 - f1: 0.8257\n",
      "Epoch 42/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1406 - f1: 0.8249\n",
      "Epoch 43/100\n",
      "100547/100547 [==============================] - 17s 174us/step - loss: 0.1419 - f1: 0.8252\n",
      "Epoch 44/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1390 - f1: 0.8262\n",
      "Epoch 45/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1385 - f1: 0.8274\n",
      "Epoch 46/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1386 - f1: 0.8275\n",
      "Epoch 47/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1370 - f1: 0.8291\n",
      "Epoch 48/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1374 - f1: 0.8293\n",
      "Epoch 49/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1354 - f1: 0.8293\n",
      "Epoch 50/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1360 - f1: 0.8317\n",
      "Epoch 51/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1352 - f1: 0.8313\n",
      "Epoch 52/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1354 - f1: 0.8317\n",
      "Epoch 53/100\n",
      "100547/100547 [==============================] - 17s 174us/step - loss: 0.1335 - f1: 0.8301\n",
      "Epoch 54/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1345 - f1: 0.8288\n",
      "Epoch 55/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1328 - f1: 0.8318\n",
      "Epoch 56/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1317 - f1: 0.8339\n",
      "Epoch 57/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1315 - f1: 0.8361\n",
      "Epoch 58/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1313 - f1: 0.8382\n",
      "Epoch 59/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1302 - f1: 0.8304\n",
      "Epoch 60/100\n",
      "100547/100547 [==============================] - 17s 174us/step - loss: 0.1314 - f1: 0.8325\n",
      "Epoch 61/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1291 - f1: 0.8312\n",
      "Epoch 62/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1294 - f1: 0.8374\n",
      "Epoch 63/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1289 - f1: 0.8394\n",
      "Epoch 64/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1277 - f1: 0.8363\n",
      "Epoch 65/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1288 - f1: 0.8360\n",
      "Epoch 66/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1269 - f1: 0.8388\n",
      "Epoch 67/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1269 - f1: 0.8344\n",
      "Epoch 68/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1254 - f1: 0.8408\n",
      "Epoch 69/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1270 - f1: 0.8385\n",
      "Epoch 70/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1253 - f1: 0.8384\n",
      "Epoch 71/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1246 - f1: 0.8390\n",
      "Epoch 72/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1245 - f1: 0.8385\n",
      "Epoch 73/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1243 - f1: 0.8404\n",
      "Epoch 74/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1242 - f1: 0.8400\n",
      "Epoch 75/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1226 - f1: 0.8452\n",
      "Epoch 76/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1231 - f1: 0.8418\n",
      "Epoch 77/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1227 - f1: 0.8415\n",
      "Epoch 78/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1216 - f1: 0.8426\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100547/100547 [==============================] - 17s 170us/step - loss: 0.1226 - f1: 0.8410\n",
      "Epoch 80/100\n",
      "100547/100547 [==============================] - 17s 169us/step - loss: 0.1220 - f1: 0.8467\n",
      "Epoch 81/100\n",
      "100547/100547 [==============================] - 17s 170us/step - loss: 0.1224 - f1: 0.8426\n",
      "Epoch 82/100\n",
      "100547/100547 [==============================] - 17s 169us/step - loss: 0.1211 - f1: 0.8433\n",
      "Epoch 83/100\n",
      "100547/100547 [==============================] - 17s 170us/step - loss: 0.1206 - f1: 0.8421\n",
      "Epoch 84/100\n",
      "100547/100547 [==============================] - 17s 169us/step - loss: 0.1207 - f1: 0.8419\n",
      "Epoch 85/100\n",
      "100547/100547 [==============================] - 17s 170us/step - loss: 0.1225 - f1: 0.8471\n",
      "Epoch 86/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1256 - f1: 0.8461\n",
      "Epoch 87/100\n",
      "100547/100547 [==============================] - 17s 170us/step - loss: 0.1267 - f1: 0.8425\n",
      "Epoch 88/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1286 - f1: 0.8439\n",
      "Epoch 89/100\n",
      "100547/100547 [==============================] - 17s 170us/step - loss: 0.1235 - f1: 0.8453\n",
      "Epoch 90/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1248 - f1: 0.8480\n",
      "Epoch 91/100\n",
      "100547/100547 [==============================] - 17s 170us/step - loss: 0.1238 - f1: 0.8517\n",
      "Epoch 92/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1240 - f1: 0.8551\n",
      "Epoch 93/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1219 - f1: 0.8551\n",
      "Epoch 94/100\n",
      "100547/100547 [==============================] - 17s 171us/step - loss: 0.1221 - f1: 0.8494\n",
      "Epoch 95/100\n",
      "100547/100547 [==============================] - 18s 175us/step - loss: 0.1214 - f1: 0.8455\n",
      "Epoch 96/100\n",
      "100547/100547 [==============================] - 18s 181us/step - loss: 0.1222 - f1: 0.8438\n",
      "Epoch 97/100\n",
      "100547/100547 [==============================] - 18s 176us/step - loss: 0.1191 - f1: 0.8498\n",
      "Epoch 98/100\n",
      "100547/100547 [==============================] - 18s 176us/step - loss: 0.1213 - f1: 0.8463\n",
      "Epoch 99/100\n",
      "100547/100547 [==============================] - 17s 173us/step - loss: 0.1209 - f1: 0.8457\n",
      "Epoch 100/100\n",
      "100547/100547 [==============================] - 17s 172us/step - loss: 0.1177 - f1: 0.8518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15bce3268d0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X1_train, y_train,batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_neural = classifier.predict(X1_test)\n",
    "result = (np.where(pred_neural>0.5,1,0)) \n",
    "print('f1_score',f1_score(y_test.values.astype(int),result.astype(int)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f1_score 0.8429056973327956\n",
    "\n",
    "pour réseaux basique \n",
    "batch_size=10, epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
