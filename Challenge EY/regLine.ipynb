{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from math import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_centre = 3760901.5068\n",
    "y_centre = -19238905.6133\n",
    "\n",
    "train = pd.read_csv('data_train.csv')\n",
    "test = pd.read_csv('data_test.csv')\n",
    "train = train.drop(['Unnamed: 0'],axis=1)\n",
    "test = test.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "def conv(time_1):   \n",
    "    sec1 = 3600*int(time_1[0:2]) + 60*int(time_1[3:5]) + int(time_1[6:8])                                                                                                                                \n",
    "    return (sec1)\n",
    "\n",
    "def distance(x1,x2,y1,y2):\n",
    "    dist = np.sqrt(((x2-x1)**2)+((y2-y1)**2))\n",
    "    return dist\n",
    "\n",
    "def ecartTemps(t1,t2):\n",
    "    ecart= t2-t1\n",
    "    return ecart\n",
    "\n",
    "def distanceCentre(x,y):\n",
    "    dx = max(0,abs(x_centre-x)-10000)\n",
    "    dy = max(0,abs(y_centre-y)-30000)\n",
    "    return (dx**2+dy**2)\n",
    "\n",
    "ecartTemps = np.vectorize(ecartTemps)\n",
    "\n",
    "distance = np.vectorize(distance)\n",
    "distanceCentre = np.vectorize(distanceCentre)\n",
    "#vitesses négatives\n",
    "\n",
    "\n",
    "\n",
    "test.vmin[test.vmin < 0] = np.NaN\n",
    "test.vmean[test.vmean < 0] = np.NaN\n",
    "test.vmax[test.vmax < 0] = np.NaN\n",
    "\n",
    "train.vmin[train.vmin < 0] = np.NaN\n",
    "train.vmean[train.vmean < 0] = np.NaN\n",
    "train.vmax[train.vmax < 0] = np.NaN\n",
    "\n",
    "#incohérences\n",
    "train['vmean'][(train.time_entry==train.time_exit)] = 0\n",
    "train['vmin'][(train.time_entry==train.time_exit)] = 0\n",
    "train['vmax'][(train.time_entry==train.time_exit)] = 0\n",
    "\n",
    "test['vmean'][(test.time_entry==test.time_exit)] = 0\n",
    "test['vmin'][(test.time_entry==test.time_exit)] = 0\n",
    "test['vmax'][(test.time_entry==test.time_exit)] = 0\n",
    "\n",
    "train['vmax'][(train.x_entry==train.x_exit)&(train.y_entry==train.y_exit)] = 0\n",
    "train['vmin'][(train.x_entry==train.x_exit)&(train.y_entry==train.y_exit)] = 0\n",
    "train['vmean'][(train.x_entry==train.x_exit)&(train.y_entry==train.y_exit)] = 0\n",
    "\n",
    "test['vmax'][(test.x_entry==test.x_exit)&(test.y_entry==test.y_exit)] = 0\n",
    "test['vmin'][(test.x_entry==test.x_exit)&(test.y_entry==test.y_exit)] = 0\n",
    "test['vmean'][(test.x_entry==test.x_exit)&(test.y_entry==test.y_exit)] = 0\n",
    "\n",
    "#incohérences 2 \n",
    "\n",
    "# train['vmean'][(train.time_entry!=train.time_exit)&(train.vmean == 0)] = np.NaN\n",
    "# train['vmin'][(train.time_entry!=train.time_exit)&(train.vmin == 0)] = np.NaN\n",
    "# train['vmax'][(train.time_entry!=train.time_exit)&(train.vmax == 0)] = np.NaN\n",
    "\n",
    "# test['vmean'][(test.time_entry!=test.time_exit)&(test.vmean == 0)] = np.NaN\n",
    "# test['vmin'][(test.time_entry!=test.time_exit)&(test.vmin == 0)] = np.NaN\n",
    "# test['vmax'][(test.time_entry!=test.time_exit)&(test.vmax == 0)] = np.NaN\n",
    "\n",
    "#train['vmax'][((train.x_entry!=train.x_exit)|(train.y_entry!=train.y_exit))&(train.vmax == 0)] = np.NaN\n",
    "#train['vmin'][((train.x_entry!=train.x_exit)|(train.y_entry!=train.y_exit))&(train.vmin == 0)] = np.NaN\n",
    "#train['vmean'][((train.x_entry!=train.x_exit)|(train.y_entry!=train.y_exit))&(train.vmean == 0)] = np.NaN\n",
    "\n",
    "#test['vmax'][((test.x_entry!=test.x_exit)|(test.y_entry!=test.y_exit))&(test.vmax == 0)] = np.NaN\n",
    "#test['vmin'][((test.x_entry!=test.x_exit)|(test.y_entry!=test.y_exit))&(test.vmin == 0)] = np.NaN\n",
    "#test['vmean'][((test.x_entry!=test.x_exit)|(test.y_entry!=test.y_exit))&(test.vmean == 0)] = np.NaN\n",
    "\n",
    "#outliers\n",
    "train.vmean = train.vmean.loc[(train.vmean<90)]\n",
    "train.vmax = train.vmean.loc[(train.vmax<90)]\n",
    "train.vmin = train.vmean.loc[(train.vmin<90)]\n",
    "\n",
    "\n",
    "#nan by mean\n",
    "# train['vmax']=train['vmax'].replace( np.NaN , train['vmax'].mean() )\n",
    "# train['vmin']=train['vmin'].replace( np.NaN , train['vmin'].mean() )\n",
    "# train['vmean']=train['vmean'].replace( np.NaN , train['vmean'].mean() )\n",
    "\n",
    "# test['vmax']=test['vmax'].replace( np.NaN , test['vmax'].mean() )\n",
    "# test['vmin']=test['vmin'].replace( np.NaN , test['vmin'].mean() )\n",
    "# test['vmean']=test['vmean'].replace( np.NaN , test['vmean'].mean() )\n",
    "\n",
    "# trainTempVmean = train.loc[(train.vmean>0)]\n",
    "# trainTempVmean = trainTempVmean.dropna()\n",
    "# trainTempVmean = trainTempVmean.vmean.mean()\n",
    "\n",
    "# trainTempVmax = train.loc[(train.vmax>0)]\n",
    "# trainTempVmax = trainTempVmax.dropna()\n",
    "# trainTempVmax = trainTempVmax.vmax.mean()\n",
    "\n",
    "# trainTempVmin = train.loc[(train.vmin>0)]\n",
    "# trainTempVmin = trainTempVmin.dropna()\n",
    "# trainTempVmin = trainTempVmin.vmin.mean()\n",
    "\n",
    "# testTempVmean = test.loc[(test.vmean>0)]\n",
    "# testTempVmean = testTempVmean.dropna()\n",
    "# testTempVmean = testTempVmean.vmean.mean()\n",
    "\n",
    "# testTempVmax = test.loc[(test.vmax>0)]\n",
    "# testTempVmax = testTempVmax.dropna()\n",
    "# testTempVmax = testTempVmax.vmax.mean()\n",
    "\n",
    "# testTempVmin = test.loc[(test.vmin>0)]\n",
    "# testTempVmin = testTempVmin.dropna()\n",
    "# testTempVmin = testTempVmin.vmin.mean()\n",
    "\n",
    "\n",
    "# train['vmax']=train['vmax'].replace( np.NaN , trainTempVmax)\n",
    "# train['vmin']=train['vmin'].replace( np.NaN , trainTempVmin)\n",
    "# train['vmean']=train['vmean'].replace( np.NaN , trainTempVmean)\n",
    "# test['vmax']=test['vmax'].replace( np.NaN , testTempVmax)\n",
    "# test['vmin']=test['vmin'].replace( np.NaN , testTempVmin)\n",
    "# test['vmean']=test['vmean'].replace( np.NaN , testTempVmean)\n",
    "\n",
    "vec_conv =  np.vectorize(conv)\n",
    "train.time_entry=vec_conv(train.time_entry)\n",
    "train.time_exit=vec_conv(train.time_exit)\n",
    "\n",
    "test.time_entry=vec_conv(test.time_entry)\n",
    "test.time_exit=vec_conv(test.time_exit)\n",
    "\n",
    "#moments\n",
    "# train['nuit']= 0\n",
    "# train['nuit'][(train.time_entry<28800)]=1\n",
    "# train['matin']= 0\n",
    "# train['matin'][(train.time_entry<43200)&(train.time_entry>28800)]=1\n",
    "# train['aprem']= 0\n",
    "# train['aprem'][(train.time_entry>=43200)]=1\n",
    "\n",
    "# test['nuit']= 0\n",
    "# test['nuit'][(test.time_entry<28800)]=1\n",
    "# test['matin']= 0\n",
    "# test['matin'][(test.time_entry<43200)&(test.time_entry>28800)]=1\n",
    "# test['aprem']= 0\n",
    "# test['aprem'][(test.time_entry>=43200)]=1\n",
    "\n",
    "train['duree']=ecartTemps(train.time_entry,train.time_exit)\n",
    "test['duree']=ecartTemps(test.time_entry,test.time_exit)\n",
    "train = train.drop(['time_entry','time_exit'],axis=1)\n",
    "test = test.drop(['time_entry','time_exit'],axis=1)\n",
    "\n",
    "#train['distCenter']=distanceCentre(train.x_entry,train.y_entry)\n",
    "#test['distCenter']=distanceCentre(test.x_entry,test.y_entry)\n",
    "\n",
    "train['distCenter_entry']=distanceCentre(train.x_entry,train.y_entry)\n",
    "test['distCenter_entry']=distanceCentre(test.x_entry,test.y_entry)\n",
    "\n",
    "train['distCenter_exit']=distanceCentre(train.x_exit,train.y_exit)\n",
    "test['distCenter_exit']=distanceCentre(test.x_exit,test.y_exit)\n",
    "\n",
    "train['Ecart_dist']=train['distCenter_exit']-train['distCenter_entry']\n",
    "test['Ecart_dist']=test['distCenter_exit']-test['distCenter_entry']\n",
    "\n",
    "train['distCenter_entry']=distanceCentre(train.x_entry,train.y_entry)\n",
    "test['distCenter_entry']=distanceCentre(test.x_entry,test.y_entry)\n",
    "\n",
    "train['distTrajet']=distance(train.x_entry,train.x_exit,train.y_entry,train.y_exit)\n",
    "test['distTrajet']=distance(test.x_entry,test.x_exit,test.y_entry,test.y_exit)\n",
    "\n",
    "\n",
    "#angles\n",
    "\n",
    "# u = np.array([train.x_exit,train.y_exit])-np.array([train.x_entry,train.y_entry])\n",
    "# v = np.array([x_centre-train.x_entry,y_centre-train.y_entry])\n",
    "\n",
    "# angle_train = []\n",
    "# for i in range(u.shape[1]):\n",
    "#     scalar = (np.dot([u[0][i],u[1][i]],[v[0][i],v[1][i]]))\n",
    "#     u_norm = (np.linalg.norm([u[0][i],u[1][i]]))\n",
    "#     v_norm = (np.linalg.norm([v[0][i],v[1][i]]))\n",
    "#     angle_train.append(degrees(acos(scalar/(u_norm*v_norm))))\n",
    "    \n",
    "# u = np.array([test.x_exit,test.y_exit])-np.array([test.x_entry,test.y_entry])\n",
    "# v = np.array([x_centre-test.x_entry,y_centre-test.y_entry])\n",
    "\n",
    "# angle_test = []\n",
    "# for i in range(u.shape[1]):\n",
    "#     scalar = (np.dot([u[0][i],u[1][i]],[v[0][i],v[1][i]]))\n",
    "#     u_norm = (np.linalg.norm([u[0][i],u[1][i]]))\n",
    "#     v_norm = (np.linalg.norm([v[0][i],v[1][i]]))\n",
    "#     angle_test.append(degrees(acos(scalar/(u_norm*v_norm))))\n",
    "\n",
    "#application\n",
    "\n",
    "# train['angle']=angle_train\n",
    "# test['angle']=angle_test\n",
    "tr = test.loc[test.x_exit.isnull()]\n",
    "train['city_center'] = 0\n",
    "train['city_center'][(train.x_exit>=3750901.5068) & (train.x_exit<=3770901.5068)&(train.y_exit>=(-19268905.6133)) & (train.y_exit<=(-19208905.6133))]=1\n",
    "\n",
    "# train.drop(['x_entry', 'x_exit','y_exit','y_entry'], axis=1, inplace=True)\n",
    "# test.drop(['x_entry', 'x_exit','y_exit','y_entry'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test=test.loc[test.x_exit.isnull()!=True]\n",
    "\n",
    "TestVmeanNan = test.loc[(test.vmean.isnull()) & (test.x_exit.isnull()!=True)]\n",
    "TestVmean = test.loc[test.vmean.isnull()!=True]\n",
    "TestVminNan = test.loc[(test.vmin.isnull()) & (test.x_exit.isnull()!=True)]\n",
    "TestVmin = test.loc[test.vmin.isnull()!=True]\n",
    "TestVmaxNan = test.loc[(test.vmax.isnull()) & (test.x_exit.isnull()!=True)]\n",
    "TestVmax = test.loc[test.vmax.isnull()!=True]\n",
    "\n",
    "VmeanNan = train.loc[train.vmean.isnull()]\n",
    "Vmean = train.loc[train.vmean.isnull()!=True]\n",
    "VminNan = train.loc[train.vmin.isnull()]\n",
    "Vmin = train.loc[train.vmin.isnull()!=True]\n",
    "VmaxNan = train.loc[train.vmax.isnull()]\n",
    "Vmax = train.loc[train.vmax.isnull()!=True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestVmeanNan.drop(['vmax', 'vmin','distCenter_exit','Ecart_dist','x_exit','y_exit','hash','trajectory_id'], axis=1, inplace=True)\n",
    "TestVmean.drop(['vmax', 'vmin','distCenter_exit','Ecart_dist','x_exit','y_exit','hash','trajectory_id'], axis=1, inplace=True)\n",
    "\n",
    "TestVminNan.drop(['vmax', 'vmean','distCenter_exit','Ecart_dist','x_exit','y_exit','hash','trajectory_id'], axis=1, inplace=True)\n",
    "TestVmin.drop(['vmax', 'vmean','distCenter_exit','Ecart_dist','x_exit','y_exit','hash','trajectory_id'], axis=1, inplace=True)\n",
    "\n",
    "TestVmaxNan.drop(['vmean', 'vmin','distCenter_exit','Ecart_dist','x_exit','y_exit','hash','trajectory_id'], axis=1, inplace=True)\n",
    "TestVmax.drop(['vmean', 'vmin','distCenter_exit','Ecart_dist','x_exit','y_exit','hash','trajectory_id'], axis=1, inplace=True)\n",
    "\n",
    "VmeanNan.drop(['vmax', 'vmin','distCenter_exit','Ecart_dist','city_center','x_exit','y_exit','hash','trajectory_id'], axis=1, inplace=True)\n",
    "Vmean.drop(['vmax', 'vmin','distCenter_exit','Ecart_dist','city_center','x_exit','y_exit','hash','trajectory_id'], axis=1, inplace=True)\n",
    "\n",
    "VminNan.drop(['vmax', 'vmean','distCenter_exit','Ecart_dist','city_center','x_exit','y_exit','hash','trajectory_id'], axis=1, inplace=True)\n",
    "Vmin.drop(['vmax', 'vmean','distCenter_exit','Ecart_dist','city_center','x_exit','y_exit','hash','trajectory_id'], axis=1, inplace=True)\n",
    "\n",
    "VmaxNan.drop(['vmean', 'vmin','distCenter_exit','Ecart_dist','city_center','x_exit','y_exit','hash','trajectory_id'], axis=1, inplace=True)\n",
    "Vmax.drop(['vmean', 'vmin','distCenter_exit','Ecart_dist','city_center','x_exit','y_exit','hash','trajectory_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NotNullVmean = Vmean.loc[Vmean.vmean!=0]\n",
    "# NotNullVmax = Vmax.loc[Vmax.vmax!=0]\n",
    "# NotNullVmin = Vmin.loc[Vmin.vmin!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestVmax = TestVmax.dropna()\n",
    "TestVmin = TestVmin.dropna()\n",
    "TestVmean = TestVmean.dropna()\n",
    "\n",
    "VmaxConcat = pd.concat([TestVmax,Vmax])\n",
    "VminConcat = pd.concat([TestVmin,Vmin])\n",
    "VmeanConcat = pd.concat([TestVmean,Vmean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "Lgb = LGBMRegressor(n_estimators=300,max_depth=8)\n",
    "Reg = LinearRegression(fit_intercept=True,normalize=True,n_jobs=-1)\n",
    "\n",
    "# speeds = [Vmean,Vmin,Vmax]\n",
    "speeds = [VmeanConcat,VminConcat,VmaxConcat]\n",
    "#speeds = [NotNullVmean,NotNullVmin,NotNullVmax]\n",
    "trainSpeedsNan =[VmeanNan,VminNan,VmaxNan]\n",
    "testSpeedsNan =[TestVmeanNan,TestVminNan,TestVmaxNan]\n",
    "TrainPreds=[]\n",
    "TestPreds=[]\n",
    "i=0\n",
    "\n",
    "for speed in speeds:\n",
    "    X = speed.iloc[:,1:].values\n",
    "    Y = speed.iloc[:,0].values\n",
    "    Lgb.fit(X,Y)\n",
    "    TrainPreds.append(Lgb.predict(trainSpeedsNan[i].iloc[:,1:]))\n",
    "    TestPreds.append(Lgb.predict(testSpeedsNan[i].iloc[:,1:]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "VmeanNan = train.loc[train.vmean.isnull()]\n",
    "VminNan = train.loc[train.vmin.isnull()]\n",
    "VmaxNan = train.loc[train.vmax.isnull()]\n",
    "VmeanNan.vmean = TrainPreds[0]\n",
    "VminNan.vmin = TrainPreds[1]\n",
    "VmaxNan.vmax = TrainPreds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestVmeanNan = test.loc[(test.vmean.isnull()) & (test.x_exit.isnull()!=True)]\n",
    "TestVminNan = test.loc[(test.vmin.isnull()) & (test.x_exit.isnull()!=True)]\n",
    "TestVmaxNan = test.loc[(test.vmax.isnull()) & (test.x_exit.isnull()!=True)]\n",
    "\n",
    "TestVmeanNan.vmean = TestPreds[0]\n",
    "TestVminNan.vmin = TestPreds[1]\n",
    "TestVmaxNan.vmax = TestPreds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vmean = pd.concat([Vmean.vmean,VmeanNan.vmean])\n",
    "Vmean = pd.DataFrame(Vmean)\n",
    "Vmean = Vmean.sort_index()\n",
    "Vmean.to_csv(\"Vmean_comb_lgb.csv\",index=False)\n",
    "\n",
    "Vmin = pd.concat([Vmin.vmin,VminNan.vmin])\n",
    "Vmin = pd.DataFrame(Vmin)\n",
    "Vmin = Vmin.sort_index()\n",
    "Vmin.to_csv(\"Vmin_comb_lgb.csv\",index=False)\n",
    "\n",
    "Vmax = pd.concat([Vmax.vmax,VmaxNan.vmax])\n",
    "Vmax = pd.DataFrame(Vmax)\n",
    "Vmax = Vmax.sort_index()\n",
    "Vmax.to_csv(\"Vmax_comb_lgb.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestVmean = pd.concat([TestVmean.vmean,TestVmeanNan.vmean,tr.vmean])\n",
    "TestVmean = pd.DataFrame(TestVmean)\n",
    "TestVmean = TestVmean.sort_index()\n",
    "TestVmean.to_csv(\"Test_Vmean_comb_lgb.csv\",index=False)\n",
    "\n",
    "TestVmin = pd.concat([TestVmin.vmin,TestVminNan.vmin,tr.vmin])\n",
    "TestVmin = pd.DataFrame(TestVmin)\n",
    "TestVmin = TestVmin.sort_index()\n",
    "TestVmin.to_csv(\"Test_Vmin_comb_lgb.csv\",index=False)\n",
    "\n",
    "TestVmax = pd.concat([TestVmax.vmax,TestVmaxNan.vmax,tr.vmax])\n",
    "TestVmax = pd.DataFrame(TestVmax)\n",
    "TestVmax = TestVmax.sort_index()\n",
    "TestVmax.to_csv(\"Test_Vmax_comb_lgb.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSpeed(df):\n",
    "    lesdataframes=[]\n",
    "\n",
    "    for vincent in df.columns[1:]:\n",
    "        print(vincent)\n",
    "        k=df\n",
    "        k = k.groupby('hash')[vincent].apply(list)\n",
    "\n",
    "        if (vincent == 'x_exit') | (vincent == 'y_exit') :\n",
    "            for i in range (k.shape[0]):\n",
    "                k[i].reverse()\n",
    "                k[i]=k[i][1:]      #x_exit y_exit  \n",
    "        if (vincent == 'vmin') | (vincent == 'vmax') | (vincent == 'vmean'):\n",
    "            for i in range (k.shape[0]):\n",
    "                k[i].reverse()\n",
    "                last = k[i][0]\n",
    "                if isnan(last):\n",
    "                    k[i][0]=-1\n",
    "        else :\n",
    "            for i in range (k.shape[0]):\n",
    "                k[i].reverse()\n",
    "\n",
    "\n",
    "        k=pd.DataFrame(k)\n",
    "\n",
    "\n",
    "        # expand df.time_entry into its own dataframe\n",
    "        gouz = k[vincent].apply(pd.Series)\n",
    "\n",
    "        # rename each variable is time_entry\n",
    "        gouz = gouz.rename(columns = lambda x : vincent + str(x))\n",
    "        \n",
    "        if (vincent == 'distCenter_entry'):\n",
    "            gouz = gouz.fillna(math.inf) #arbre sinon il faudra mettre -1 ou tres grand\n",
    "        else:\n",
    "            gouz = gouz.fillna(0)\n",
    "        \n",
    "        \n",
    "        lesdataframes.append(gouz)\n",
    "\n",
    "    r = pd.concat(lesdataframes,axis=1)\n",
    "    r = r.reset_index()\n",
    "    r = r.drop(['hash'],axis=1)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.vmax =Vmax\n",
    "train.vmin =Vmin\n",
    "train.vmean =Vmean\n",
    "\n",
    "test.vmax =TestVmax\n",
    "test.vmin =TestVmin\n",
    "test.vmean =TestVmean\n",
    "#supprimer et garder vmax_0 vmin et vmean pour tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['distCenter_exit','Ecart_dist','city_center','trajectory_id','distTrajet'], axis=1, inplace=True)\n",
    "test.drop(['distCenter_exit','Ecart_dist','trajectory_id','distTrajet'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmax\n",
      "vmin\n",
      "vmean\n",
      "x_entry\n",
      "y_entry\n",
      "x_exit\n",
      "y_exit\n",
      "duree\n",
      "distCenter_entry\n",
      "vmax\n",
      "vmin\n",
      "vmean\n",
      "x_entry\n",
      "y_entry\n",
      "x_exit\n",
      "y_exit\n",
      "duree\n",
      "distCenter_entry\n"
     ]
    }
   ],
   "source": [
    "X = findSpeed(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmax\n",
      "vmin\n",
      "vmean\n",
      "x_entry\n",
      "y_entry\n",
      "x_exit\n",
      "y_exit\n",
      "duree\n",
      "distCenter_entry\n"
     ]
    }
   ],
   "source": [
    "X_test = findSpeed(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yvmax = X.vmax0\n",
    "Yvmin = X.vmin0\n",
    "Yvmean = X.vmean0\n",
    "\n",
    "Yvmax.to_csv('TrainVmax0.csv',index=False)\n",
    "Yvmin.to_csv('TrainVmin0.csv',index=False)\n",
    "Yvmean.to_csv('TrainVmean0.csv',index=False)\n",
    "\n",
    "X.drop(['vmax0', 'vmean0','vmin0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToKeepTestVmax = X_test.loc[X_test.vmax0!=-1].iloc[:,0]\n",
    "ToPredTestVmax = X_test.loc[X_test.vmax0==-1].iloc[:,1:]\n",
    "ToPredTestVmax.drop(ToPredTestVmax.columns[19:59],axis=1,inplace=True)\n",
    "\n",
    "ToKeepTestVmin = X_test.loc[X_test.vmin0!=-1]['vmin0']\n",
    "ToPredTestVmin = X_test.loc[X_test.vmin0==-1]\n",
    "ToPredTestVmin.drop(ToPredTestVmin.columns[0:21],axis=1,inplace=True)\n",
    "ToPredTestVmin.drop(ToPredTestVmin.columns[19:39],axis=1,inplace=True)\n",
    "\n",
    "ToKeepTestVmean = X_test.loc[X_test.vmean0!=-1]['vmean0']\n",
    "ToPredTestVmean = X_test.loc[X_test.vmean0==-1]\n",
    "ToPredTestVmean.drop(ToPredTestVmean.columns[0:41],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "XVmax = X.drop(X.columns[19:57], axis=1)\n",
    "\n",
    "XVmin = X.drop(X.columns[0:19], axis=1)\n",
    "XVmin = XVmin.drop(XVmin.columns[19:38], axis=1)\n",
    "\n",
    "XVmean = X.drop(X.columns[0:19], axis=1)\n",
    "XVmean = XVmean.drop(XVmean.columns[0:19], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:  1.1min remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  1.1min remaining:   27.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM :  0.618111637116491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lgb=LGBMRegressor(n_jobs=-1,n_estimators=500)\n",
    "print('LGBM : ',(cross_val_score(lgb, XVmax, Yvmax, cv=10,verbose=3, scoring='r2',n_jobs=-1)).mean())\n",
    "#0.5289348098049762 200 esti\n",
    "#0.527016138207685 150 esti\n",
    "#0.5310225033857917"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XVmax = XVmax.drop(XVmax.columns[-19:], axis=1)\n",
    "# XVmax = XVmax.drop(XVmax.columns[98:-1], axis=1)\n",
    "# XVmax = XVmax.drop(XVmax.columns[19:-2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-04 21:09:16.234572\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed: 47.3min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 74.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.535961409338884\n",
      "{'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 1000, 'n_jobs': -1}\n",
      "2019-05-04 22:23:37.397330\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "X = XVmax\n",
    "y = Yvmax\n",
    "param_grid = {\n",
    "    'n_jobs':[-1],\n",
    "    'n_estimators': [300,500,1000],\n",
    "    'learning_rate': [0.001,0.01,0.05,0.1],\n",
    "    'max_depth': [5,6,8,10]\n",
    "}\n",
    "\n",
    "#kf = StratifiedKFold(n_splits=10,random_state=1,shuffle=True)\n",
    "model = GridSearchCV(LGBMRegressor(),param_grid, cv=10,verbose=3, scoring= 'r2',n_jobs=-1)\n",
    "model.fit(X,y)\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
