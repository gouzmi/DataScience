{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from math import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_centre = 3760901.5068\n",
    "y_centre = -19238905.6133\n",
    "\n",
    "train = pd.read_csv('data_train.csv')\n",
    "test = pd.read_csv('data_test.csv')\n",
    "train = train.drop(['Unnamed: 0'],axis=1)\n",
    "test = test.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "tr = test.loc[test.x_exit.isnull()]\n",
    "\n",
    "def conv(time_1):   \n",
    "    sec1 = 3600*int(time_1[0:2]) + 60*int(time_1[3:5]) + int(time_1[6:8])                                                                                                                                \n",
    "    return (sec1)\n",
    "\n",
    "def distance(x1,x2,y1,y2):\n",
    "    dist = np.sqrt(((x2-x1)**2)+((y2-y1)**2))\n",
    "    return dist\n",
    "\n",
    "def ecartTemps(t1,t2):\n",
    "    ecart= t2-t1\n",
    "    return ecart\n",
    "\n",
    "def distanceCentre(x,y):\n",
    "    dx = max(0,abs(x_centre-x)-10000)\n",
    "    dy = max(0,abs(y_centre-y)-30000)\n",
    "    return (dx**2+dy**2)\n",
    "\n",
    "ecartTemps = np.vectorize(ecartTemps)\n",
    "\n",
    "distance = np.vectorize(distance)\n",
    "distanceCentre = np.vectorize(distanceCentre)\n",
    "#vitesses négatives\n",
    "\n",
    "test.vmin[test.vmin < 0] = np.NaN\n",
    "test.vmean[test.vmean < 0] = np.NaN\n",
    "test.vmax[test.vmax < 0] = np.NaN\n",
    "\n",
    "train.vmin[train.vmin < 0] = np.NaN\n",
    "train.vmean[train.vmean < 0] = np.NaN\n",
    "train.vmax[train.vmax < 0] = np.NaN\n",
    "\n",
    "#incohérences\n",
    "train['vmean'][(train.time_entry==train.time_exit)] = 0\n",
    "train['vmin'][(train.time_entry==train.time_exit)] = 0\n",
    "train['vmax'][(train.time_entry==train.time_exit)] = 0\n",
    "\n",
    "test['vmean'][(test.time_entry==test.time_exit)] = 0\n",
    "test['vmin'][(test.time_entry==test.time_exit)] = 0\n",
    "test['vmax'][(test.time_entry==test.time_exit)] = 0\n",
    "\n",
    "train['vmax'][(train.x_entry==train.x_exit)&(train.y_entry==train.y_exit)] = 0\n",
    "train['vmin'][(train.x_entry==train.x_exit)&(train.y_entry==train.y_exit)] = 0\n",
    "train['vmean'][(train.x_entry==train.x_exit)&(train.y_entry==train.y_exit)] = 0\n",
    "\n",
    "test['vmax'][(test.x_entry==test.x_exit)&(test.y_entry==test.y_exit)] = 0\n",
    "test['vmin'][(test.x_entry==test.x_exit)&(test.y_entry==test.y_exit)] = 0\n",
    "test['vmean'][(test.x_entry==test.x_exit)&(test.y_entry==test.y_exit)] = 0\n",
    "\n",
    "#outliers\n",
    "train.vmean = train.vmean.loc[(train.vmean<90)]\n",
    "train.vmax = train.vmean.loc[(train.vmax<90)]\n",
    "train.vmin = train.vmean.loc[(train.vmin<90)]\n",
    "\n",
    "\n",
    "#nan by mean\n",
    "train['vmax']=train['vmax'].replace( np.NaN , train['vmax'].mean() )\n",
    "train['vmin']=train['vmin'].replace( np.NaN , train['vmin'].mean() )\n",
    "train['vmean']=train['vmean'].replace( np.NaN , train['vmean'].mean() )\n",
    "\n",
    "test['vmax']=test['vmax'].replace( np.NaN , test['vmax'].mean() )\n",
    "test['vmin']=test['vmin'].replace( np.NaN , test['vmin'].mean() )\n",
    "test['vmean']=test['vmean'].replace( np.NaN , test['vmean'].mean() )\n",
    "\n",
    "# trainTempVmean = train.loc[(train.vmean>0)]\n",
    "# trainTempVmean = trainTempVmean.dropna()\n",
    "# trainTempVmean = trainTempVmean.vmean.mean()\n",
    "\n",
    "# trainTempVmax = train.loc[(train.vmax>0)]\n",
    "# trainTempVmax = trainTempVmax.dropna()\n",
    "# trainTempVmax = trainTempVmax.vmax.mean()\n",
    "\n",
    "# trainTempVmin = train.loc[(train.vmin>0)]\n",
    "# trainTempVmin = trainTempVmin.dropna()\n",
    "# trainTempVmin = trainTempVmin.vmin.mean()\n",
    "\n",
    "# testTempVmean = test.loc[(test.vmean>0)]\n",
    "# testTempVmean = testTempVmean.dropna()\n",
    "# testTempVmean = testTempVmean.vmean.mean()\n",
    "\n",
    "# testTempVmax = test.loc[(test.vmax>0)]\n",
    "# testTempVmax = testTempVmax.dropna()\n",
    "# testTempVmax = testTempVmax.vmax.mean()\n",
    "\n",
    "# testTempVmin = test.loc[(test.vmin>0)]\n",
    "# testTempVmin = testTempVmin.dropna()\n",
    "# testTempVmin = testTempVmin.vmin.mean()\n",
    "\n",
    "\n",
    "# train['vmax']=train['vmax'].replace( np.NaN , trainTempVmax)\n",
    "# train['vmin']=train['vmin'].replace( np.NaN , trainTempVmin)\n",
    "# train['vmean']=train['vmean'].replace( np.NaN , trainTempVmean)\n",
    "# test['vmax']=test['vmax'].replace( np.NaN , testTempVmax)\n",
    "# test['vmin']=test['vmin'].replace( np.NaN , testTempVmin)\n",
    "# test['vmean']=test['vmean'].replace( np.NaN , testTempVmean)\n",
    "\n",
    "vec_conv =  np.vectorize(conv)\n",
    "train.time_entry=vec_conv(train.time_entry)\n",
    "train.time_exit=vec_conv(train.time_exit)\n",
    "\n",
    "test.time_entry=vec_conv(test.time_entry)\n",
    "test.time_exit=vec_conv(test.time_exit)\n",
    "\n",
    "train['duree']=ecartTemps(train.time_entry,train.time_exit)\n",
    "test['duree']=ecartTemps(test.time_entry,test.time_exit)\n",
    "train = train.drop(['time_entry','time_exit'],axis=1)\n",
    "test = test.drop(['time_entry','time_exit'],axis=1)\n",
    "\n",
    "# train['center']=distance(x_centre,train.x_entry,y_centre,train.y_entry)\n",
    "# test['center']=distance(x_centre,test.x_entry,y_centre,test.y_entry)\n",
    "\n",
    "train['distCenter']=distanceCentre(train.x_entry,train.y_entry)\n",
    "test['distCenter']=distanceCentre(test.x_entry,test.y_entry)\n",
    "\n",
    "\n",
    "# #(3750901.5068+3770901.5068)/2 x centre\n",
    "# # = 3760901.5068\n",
    "# #(-19268905.6133+-19208905.6133)/2\n",
    "# # = -19238905.6133\n",
    "# Center = distance(train.x_entry,3760901.5068,train.y_entry,-19238905.6133)\n",
    "# train['Center'] = Center\n",
    "\n",
    "train['city_center'] = 0\n",
    "train['city_center'][(train.x_exit>=3750901.5068) & (train.x_exit<=3770901.5068)&(train.y_exit>=(-19268905.6133)) & (train.y_exit<=(-19208905.6133))]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y=train\n",
    "# Y = Y.groupby('hash')['city_center'].apply(list)\n",
    "# for i in range (Y.shape[0]):\n",
    "#     Y[i]=Y[i][-1]\n",
    "\n",
    "# Y=pd.DataFrame(Y)\n",
    "# Y = pd.DataFrame(Y.values)\n",
    "\n",
    "#Y.to_csv(\"Y.csv\",index=False)\n",
    "\n",
    "train = train.drop(['city_center'],axis=1)\n",
    "train = train.drop(['trajectory_id'],axis=1)\n",
    "test = test.drop(['trajectory_id'],axis=1)\n",
    "\n",
    "\n",
    "def transformOnLine(df):\n",
    "    lesdataframes=[]\n",
    "\n",
    "    for vincent in df.columns[1:]:\n",
    "        print(vincent)\n",
    "        k=df\n",
    "        k = k.groupby('hash')[vincent].apply(list)\n",
    "\n",
    "        if (vincent == 'x_exit') | (vincent == 'y_exit'):\n",
    "            for i in range (k.shape[0]):\n",
    "                k[i].reverse()\n",
    "                k[i]=k[i][1:]      #x_exit y_exit\n",
    "        else :\n",
    "            for i in range (k.shape[0]):\n",
    "                k[i].reverse()\n",
    "\n",
    "\n",
    "        k=pd.DataFrame(k)\n",
    "\n",
    "\n",
    "        # expand df.time_entry into its own dataframe\n",
    "        gouz = k[vincent].apply(pd.Series)\n",
    "\n",
    "        # rename each variable is time_entry\n",
    "        gouz = gouz.rename(columns = lambda x : 'tag_' + str(x))\n",
    "        \n",
    "        if(vincent == 'distCenter'):\n",
    "            gouz = gouz.fillna(math.inf)\n",
    "        else:\n",
    "            gouz = gouz.fillna(0)\n",
    "        \n",
    "        lesdataframes.append(gouz)\n",
    "\n",
    "    r = pd.concat(lesdataframes,axis=1)\n",
    "    r = r.reset_index()\n",
    "    r = r.drop(['hash'],axis=1)\n",
    "    r.columns = np.arange(len(r.columns))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = transformOnLine(train)\n",
    "# X_test = transformOnLine(test)\n",
    "# X.to_csv(\"X.csv\",index=False)\n",
    "# X_test.to_csv(\"X_test.csv\",index=False)\n",
    "X =pd.read_csv('X.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "Y = pd.read_csv('Y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X1, Y, test_size=0.25, random_state=1)\n",
    "# clf = XGBClassifier()\n",
    "# clf.fit(X_train,y_train)\n",
    "# pred = clf.predict(X_test)\n",
    "# print('f1_score',f1_score(y_test.values.astype(int),pred.astype(int)))\n",
    "# #0.8783700809377617 baseline\n",
    "# #0.8795344106678721 distance au centre\n",
    "# #0.8818456969904631 distance au rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# centre\n",
    "# 20000\n",
    "# sur 60000\n",
    "# #calculs des angles\n",
    "\n",
    "# #X[14] X[15] x et y entry\n",
    "# #X[16] X[17] x et y exit\n",
    "# #(3750901.5068+3770901.5068)/2 x centre\n",
    "# # = 3760901.5068\n",
    "# #(-19268905.6133+-19208905.6133)/2\n",
    "# # = -19238905.6133\n",
    "\n",
    "# u = np.array([X[16],X[17]])-np.array([X[14],X[15]])\n",
    "# v = np.array([3760901.5068-X[14],-19238905.6133-X[15]])\n",
    "\n",
    "# angle_train = []\n",
    "# for i in range(u.shape[1]):\n",
    "#     scalar = (np.dot([u[0][i],u[1][i]],[v[0][i],v[1][i]]))\n",
    "#     u_norm = (np.linalg.norm([u[0][i],u[1][i]]))\n",
    "#     v_norm = (np.linalg.norm([v[0][i],v[1][i]]))\n",
    "#     angle_train.append(degrees(acos(scalar/(u_norm*v_norm))))\n",
    "    \n",
    "# u = np.array([X_test[16],X_test[17]])-np.array([X_test[14],X_test[15]])\n",
    "# v = np.array([3760901.5068-X_test[14],-19238905.6133-X_test[15]])\n",
    "\n",
    "# angle_test = []\n",
    "# for i in range(u.shape[1]):\n",
    "#     scalar = (np.dot([u[0][i],u[1][i]],[v[0][i],v[1][i]]))\n",
    "#     u_norm = (np.linalg.norm([u[0][i],u[1][i]]))\n",
    "#     v_norm = (np.linalg.norm([v[0][i],v[1][i]]))\n",
    "#     angle_test.append(degrees(acos(scalar/(u_norm*v_norm))))\n",
    "\n",
    "# #application\n",
    "\n",
    "# X['angle']=angle_train\n",
    "# X_test['angle']=angle_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# #GRID SEARCH\n",
    "\n",
    "# print(datetime.datetime.now())\n",
    "# X = X\n",
    "# y = Y.astype(int)\n",
    "# param_grid = {\n",
    "#     'num_boost_round': [60,70,90,150,300],\n",
    "#     'eta': [0.1,0.15,0.2],\n",
    "#     'max_depth': [8,10,12,15,20],\n",
    "#     'min_child_weight': [0.4,0.5],\n",
    "#     'n_jobs':[-1],\n",
    "#     'colsample_bytree':[0.3,0.5,0.8],\n",
    "#     'subsample' :[0.8,1],\n",
    "#     'gamma' :[0,1,5]\n",
    "# }\n",
    "# XGBClassifier()\n",
    "\n",
    "# kf = StratifiedKFold(n_splits=3,random_state=1,shuffle=True)\n",
    "# random_search = RandomizedSearchCV(XGBClassifier(),param_grid,n_iter=7, cv=kf.split(X, y),verbose=3, scoring= 'f1',iid=True,n_jobs=-1)\n",
    "# random_search.fit(X,y)\n",
    "\n",
    "# print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "X = X\n",
    "y = Y.astype(int)\n",
    "param_grid = {\n",
    "    'n_jobs':[-1],\n",
    "    'n_estimators': [70,90,110],\n",
    "    'eta': [0.01,0.05,0.1],\n",
    "    'max_depth': [14,15,16],\n",
    "    'min_child_weight': [0.4,0.5],\n",
    "    'n_jobs':[-1],\n",
    "    'colsample_bytree':[0.3,0.5],\n",
    "    'subsample' :[1],\n",
    "    'gamma' :[5]\n",
    "}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10,random_state=1,shuffle=True)\n",
    "model = GridSearchCV(XGBClassifier(),param_grid, cv=kf.split(X, y),verbose=3, scoring= 'f1',iid=True,n_jobs=-1)\n",
    "model.fit(X,y)\n",
    "\n",
    "print (model.best_score_\n",
    "print (model.best_params_)\n",
    "print(pd.DataFrame(model.cv_results_))\n",
    "\n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pickle.load(open('V2_XGB_best.pickle', 'rb'))\n",
    "pickle.dump(model.best_estimator_,open('XGB_best_5','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.best_estimator_.predict(X_test)\n",
    "prediction = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_id = tr['trajectory_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_id=trajectory_id.values\n",
    "prediction['id']=trajectory_id\n",
    "prediction['target']=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.target = prediction.target.astype(int)\n",
    "prediction.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv(\"OL_XGB_good3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 1ère Version\n",
    "# print(model.best_params_)\n",
    "{'eta': 0.1, 'max_depth': 8, 'min_child_weight': 0.5, 'n_jobs': -1, 'num_boost_round': 100}\n",
    "\n",
    "# 2ème Version\n",
    "# print(model.best_params_)\n",
    "{'eta': 0.2, 'max_depth': 8, 'min_child_weight': 0.5, 'n_jobs': -1, 'num_boost_round': 70}\n",
    "\n",
    "# 3ème\n",
    "{'eta': 0.2, 'max_depth': 8, 'min_child_weight': 0.4, 'n_jobs': -1, 'num_boost_round': 70}\n",
    "\n",
    "# 4ème version randomSearch\n",
    "{'subsample': 1,\n",
    " 'num_boost_round': 90,\n",
    " 'n_jobs': -1,\n",
    " 'min_child_weight': 0.5,\n",
    " 'max_depth': 11,\n",
    " 'gamma': 5,\n",
    " 'eta': 0.15,\n",
    " 'colsample_bytree': 0.8}\n",
    " \n",
    " #Gridsearch\n",
    " {'colsample_bytree': 0.5,\n",
    " 'eta': 0.1,\n",
    " 'gamma': 5,\n",
    " 'max_depth': 15,\n",
    " 'min_child_weight': 0.5,\n",
    " 'n_jobs': -1,\n",
    " 'num_boost_round': 70,\n",
    " 'subsample': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = XGBClassifier()\n",
    "# clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = clf.predict(X_test)\n",
    "# prediction = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot\n",
    "# pyplot.bar(range(len(clf.feature_importances_[np.argsort(clf.feature_importances_)[-10:]])), clf.feature_importances_[np.argsort(clf.feature_importances_)[-10:]])\n",
    "# pyplot.show()\n",
    "# np.argsort(clf.feature_importances_)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import theano # utilise à la fois le Cpu et le Gpu de l'ordinateur\n",
    "# import keras\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X1=scaler.fit_transform(X)\n",
    "# X1_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Build_Classif ():\n",
    "#     classifier = Sequential()\n",
    "#     classifier.add(Dense(units=89,activation=\"relu\",kernel_initializer=\"uniform\",input_dim=178)) #1ere couche\n",
    "#     classifier.add(Dense(units=89,activation=\"relu\",kernel_initializer=\"uniform\")) #couche cachée\n",
    "#     classifier.add(Dense(units=1,activation=\"sigmoid\",kernel_initializer=\"uniform\")) #to get a proba\n",
    "#     classifier.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "#     return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = KerasClassifier(build_fn=Build_Classif,batch_size=, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
