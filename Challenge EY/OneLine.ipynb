{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from math import *\n",
    "\n",
    "train = pd.read_csv('data_train.csv')\n",
    "test = pd.read_csv('data_test.csv')\n",
    "train = train.drop(['Unnamed: 0'],axis=1)\n",
    "test = test.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "tr = test.loc[test.x_exit.isnull()]\n",
    "\n",
    "def conv(time_1):   \n",
    "    sec1 = 3600*int(time_1[0:2]) + 60*int(time_1[3:5]) + int(time_1[6:8])                                                                                                                                \n",
    "    return (sec1)\n",
    "\n",
    "# vec_conv =  np.vectorize(conv)\n",
    "# train.time_entry=vec_conv(train.time_entry)\n",
    "# train.time_exit=vec_conv(train.time_exit)\n",
    "\n",
    "#incohérences\n",
    "train['vmean'][(train.time_entry==train.time_exit)] = 0\n",
    "train['vmin'][(train.time_entry==train.time_exit)] = 0\n",
    "train['vmax'][(train.time_entry==train.time_exit)] = 0\n",
    "\n",
    "test['vmean'][(test.time_entry==test.time_exit)] = 0\n",
    "test['vmin'][(test.time_entry==test.time_exit)] = 0\n",
    "test['vmax'][(test.time_entry==test.time_exit)] = 0\n",
    "\n",
    "train['vmax'][(train.x_entry==train.x_exit)&(train.y_entry==train.y_exit)] = 0\n",
    "train['vmin'][(train.x_entry==train.x_exit)&(train.y_entry==train.y_exit)] = 0\n",
    "train['vmean'][(train.x_entry==train.x_exit)&(train.y_entry==train.y_exit)] = 0\n",
    "\n",
    "test['vmax'][(test.x_entry==test.x_exit)&(test.y_entry==test.y_exit)] = 0\n",
    "test['vmin'][(test.x_entry==test.x_exit)&(test.y_entry==test.y_exit)] = 0\n",
    "test['vmean'][(test.x_entry==test.x_exit)&(test.y_entry==test.y_exit)] = 0\n",
    "\n",
    "#outliers\n",
    "train.vmean = train.vmean.loc[(train.vmean<90) & (train.vmean>=0)]\n",
    "train.vmax = train.vmean.loc[(train.vmax<90) & (train.vmax>=0)]\n",
    "train.vmin = train.vmean.loc[(train.vmin<90) & (train.vmin>=0)]\n",
    "\n",
    "#nan by mean\n",
    "train['vmax']=train['vmax'].replace( np.NaN , train['vmax'].mean() )\n",
    "train['vmin']=train['vmin'].replace( np.NaN , train['vmin'].mean() )\n",
    "train['vmean']=train['vmean'].replace( np.NaN , train['vmean'].mean() )\n",
    "\n",
    "test['vmax']=test['vmax'].replace( np.NaN , test['vmax'].mean() )\n",
    "test['vmin']=test['vmin'].replace( np.NaN , test['vmin'].mean() )\n",
    "test['vmean']=test['vmean'].replace( np.NaN , test['vmean'].mean() )\n",
    "\n",
    "# trainTempVmean = train.loc[(train.vmean>0)]\n",
    "# trainTempVmean = trainTempVmean.dropna()\n",
    "# trainTempVmean = trainTempVmean.vmean.mean()\n",
    "\n",
    "# trainTempVmax = train.loc[(train.vmax>0)]\n",
    "# trainTempVmax = trainTempVmax.dropna()\n",
    "# trainTempVmax = trainTempVmax.vmax.mean()\n",
    "\n",
    "# trainTempVmin = train.loc[(train.vmin>0)]\n",
    "# trainTempVmin = trainTempVmin.dropna()\n",
    "# trainTempVmin = trainTempVmin.vmin.mean()\n",
    "\n",
    "# testTempVmean = test.loc[(test.vmean>0)]\n",
    "# testTempVmean = testTempVmean.dropna()\n",
    "# testTempVmean = testTempVmean.vmean.mean()\n",
    "\n",
    "# testTempVmax = test.loc[(test.vmax>0)]\n",
    "# testTempVmax = testTempVmax.dropna()\n",
    "# testTempVmax = testTempVmax.vmax.mean()\n",
    "\n",
    "# testTempVmin = test.loc[(test.vmin>0)]\n",
    "# testTempVmin = testTempVmin.dropna()\n",
    "# testTempVmin = testTempVmin.vmin.mean()\n",
    "\n",
    "\n",
    "# train['vmax']=train['vmax'].replace( np.NaN , trainTempVmax)\n",
    "# train['vmin']=train['vmin'].replace( np.NaN , trainTempVmin)\n",
    "# train['vmean']=train['vmean'].replace( np.NaN , trainTempVmean)\n",
    "# test['vmax']=test['vmax'].replace( np.NaN , testTempVmax)\n",
    "# test['vmin']=test['vmin'].replace( np.NaN , testTempVmin)\n",
    "# test['vmean']=test['vmean'].replace( np.NaN , testTempVmean)\n",
    "\n",
    "vec_conv =  np.vectorize(conv)\n",
    "train.time_entry=vec_conv(train.time_entry)\n",
    "train.time_exit=vec_conv(train.time_exit)\n",
    "\n",
    "test.time_entry=vec_conv(test.time_entry)\n",
    "test.time_exit=vec_conv(test.time_exit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train['city_center'] = 0\n",
    "train['city_center'][(train.x_exit>=3750901.5068) & (train.x_exit<=3770901.5068)&(train.y_exit>=(-19268905.6133)) & (train.y_exit<=(-19208905.6133))]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=train\n",
    "Y = Y.groupby('hash')['city_center'].apply(list)\n",
    "for i in range (Y.shape[0]):\n",
    "    Y[i]=Y[i][-1]\n",
    "\n",
    "Y=pd.DataFrame(Y)\n",
    "Y = pd.DataFrame(Y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['city_center'],axis=1)\n",
    "train = train.drop(['trajectory_id'],axis=1)\n",
    "test = test.drop(['trajectory_id'],axis=1)\n",
    "\n",
    "def transformOnLine(df,):\n",
    "    lesdataframes=[]\n",
    "\n",
    "    for vincent in df.columns[1:]:\n",
    "        print(vincent)\n",
    "        k=df\n",
    "        k = k.groupby('hash')[vincent].apply(list)\n",
    "\n",
    "        if (vincent == 'x_exit') | (vincent == 'y_exit'):\n",
    "            for i in range (k.shape[0]):\n",
    "                k[i].reverse()\n",
    "                k[i]=k[i][1:]      #x_exit y_exit\n",
    "        else :\n",
    "            for i in range (k.shape[0]):\n",
    "                k[i].reverse()\n",
    "\n",
    "\n",
    "        k=pd.DataFrame(k)\n",
    "\n",
    "\n",
    "        # expand df.time_entry into its own dataframe\n",
    "        gouz = k[vincent].apply(pd.Series)\n",
    "\n",
    "        # rename each variable is time_entry\n",
    "        gouz = gouz.rename(columns = lambda x : 'tag_' + str(x))\n",
    "        gouz = gouz.fillna(0)\n",
    "        lesdataframes.append(gouz)\n",
    "\n",
    "    r = pd.concat(lesdataframes,axis=1)\n",
    "    r = r.reset_index()\n",
    "    r = r.drop(['hash'],axis=1)\n",
    "    r.columns = np.arange(len(r.columns))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_entry\n",
      "time_exit\n",
      "vmax\n",
      "vmin\n",
      "vmean\n",
      "x_entry\n",
      "y_entry\n",
      "x_exit\n",
      "y_exit\n",
      "time_entry\n",
      "time_exit\n",
      "vmax\n",
      "vmin\n",
      "vmean\n",
      "x_entry\n",
      "y_entry\n",
      "x_exit\n",
      "y_exit\n"
     ]
    }
   ],
   "source": [
    "X = transformOnLine(train)\n",
    "X_test = transformOnLine(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# #calculs des angles\n",
    "\n",
    "# #X[14] X[15] x et y entry\n",
    "# #X[16] X[17] x et y exit\n",
    "# #(3750901.5068+3770901.5068)/2 x centre\n",
    "# # = 3760901.5068\n",
    "# #(-19268905.6133+-19208905.6133)/2\n",
    "# # = -19238905.6133\n",
    "\n",
    "# u = np.array([X[16],X[17]])-np.array([X[14],X[15]])\n",
    "# v = np.array([3760901.5068-X[14],-19238905.6133-X[15]])\n",
    "\n",
    "# angle_train = []\n",
    "# for i in range(u.shape[1]):\n",
    "#     scalar = (np.dot([u[0][i],u[1][i]],[v[0][i],v[1][i]]))\n",
    "#     u_norm = (np.linalg.norm([u[0][i],u[1][i]]))\n",
    "#     v_norm = (np.linalg.norm([v[0][i],v[1][i]]))\n",
    "#     angle_train.append(degrees(acos(scalar/(u_norm*v_norm))))\n",
    "    \n",
    "# u = np.array([X_test[16],X_test[17]])-np.array([X_test[14],X_test[15]])\n",
    "# v = np.array([3760901.5068-X_test[14],-19238905.6133-X_test[15]])\n",
    "\n",
    "# angle_test = []\n",
    "# for i in range(u.shape[1]):\n",
    "#     scalar = (np.dot([u[0][i],u[1][i]],[v[0][i],v[1][i]]))\n",
    "#     u_norm = (np.linalg.norm([u[0][i],u[1][i]]))\n",
    "#     v_norm = (np.linalg.norm([v[0][i],v[1][i]]))\n",
    "#     angle_test.append(degrees(acos(scalar/(u_norm*v_norm))))\n",
    "\n",
    "# #application\n",
    "\n",
    "# X['angle']=angle_train\n",
    "# X_test['angle']=angle_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-19 01:08:50.621153\n",
      "\n",
      "1 of kfold 5\n",
      "2019-04-19 01:08:50.668196\n",
      "-------\n",
      "{'eta': 0.2, 'max_depth': 10, 'min_child_weight': 0.5, 'n_jobs': -1, 'num_boost_round': 50}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f1_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-222-fad3605fe3b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxvl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f1_score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myvl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f1_score' is not defined"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "# print(datetime.datetime.now())\n",
    "# X = X\n",
    "# y = Y\n",
    "# param_grid = {\n",
    "#     'num_boost_round': [50,70,100],\n",
    "#     'eta': [0.2,0.1],\n",
    "#     'max_depth': [8,10],\n",
    "#     'min_child_weight': [0.25,0.5,1],\n",
    "#     'n_jobs':[-1]\n",
    "# }\n",
    "\n",
    "# i=1\n",
    "# kf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)\n",
    "\n",
    "# for train_index,test_index in kf.split(X,y):\n",
    "#     print('\\n{} of kfold {}'.format(i,kf.n_splits))\n",
    "#     print(datetime.datetime.now())\n",
    "#     xtr,xvl = X.loc[train_index],X.loc[test_index]\n",
    "#     ytr,yvl = y[train_index],y[test_index]\n",
    "#     model = GridSearchCV(XGBClassifier(), param_grid, cv=5, scoring= 'f1',iid=True)\n",
    "#     print ('-------')\n",
    "#     model.fit(xtr, ytr)\n",
    "#     print (model.best_params_)\n",
    "#     pred=model.predict(xvl)\n",
    "#     print('f1score',f1_score(yvl,pred))\n",
    "#     i+=1\n",
    "    \n",
    "\n",
    "# print('----------')\n",
    "# print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pickle.load(open('XGB_best.pickle', 'rb'))\n",
    "pickle.dump(model,open('XGB_best_2','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.best_estimator_.predict(X_test)\n",
    "prediction = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_id = tr['trajectory_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_id=trajectory_id.values\n",
    "prediction['id']=trajectory_id\n",
    "prediction['target']=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33515.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.280829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.449411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             target\n",
       "count  33515.000000\n",
       "mean       0.280829\n",
       "std        0.449411\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.target = prediction.target.astype(int)\n",
    "prediction.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv(\"OL_XGB_default.csv\",index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 1ère Version\n",
    "# print(model.best_params_)\n",
    "{'eta': 0.1, 'max_depth': 8, 'min_child_weight': 0.5, 'n_jobs': -1, 'num_boost_round': 100}\n",
    "\n",
    "# 2ème Version\n",
    "# print(model.best_params_)\n",
    "{'eta': 0.2, 'max_depth': 8, 'min_child_weight': 0.5, 'n_jobs': -1, 'num_boost_round': 70}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24103\n",
       "1     9412\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)\n",
    "prediction = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([123, 103,  60, 101,  40, 122, 121, 102, 100, 120], dtype=int64)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.bar(range(len(clf.feature_importances_[np.argsort(clf.feature_importances_)[-10:]])), clf.feature_importances_[np.argsort(clf.feature_importances_)[-10:]])\n",
    "pyplot.show()\n",
    "np.argsort(clf.feature_importances_)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\gouzm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import theano # utilise à la fois le Cpu et le Gpu de l'ordinateur\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X1=scaler.fit_transform(X)\n",
    "X1_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Classif ():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units=89,activation=\"relu\",kernel_initializer=\"uniform\",input_dim=178)) #1ere couche\n",
    "    classifier.add(Dense(units=89,activation=\"relu\",kernel_initializer=\"uniform\")) #couche cachée\n",
    "    classifier.add(Dense(units=1,activation=\"sigmoid\",kernel_initializer=\"uniform\")) #to get a proba\n",
    "    classifier.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn=Build_Classif,batch_size=, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
